<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Taotao's Zone</title>
  <meta name="baidu-site-verification" content="6b2f48c1baf35f9e0eb29b4455265203"/>
  <meta name="baidu-site-verification" content="hgXDOPtWLn" />
  <meta name="google-site-verification" content="YqjJD80rZQfugWoznvslaHlII_viwiMiUDEEgPTLEDw" />
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <script src="/files/dc3da690b0d2a5655a8d6150862a2a07.html"></script>
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile-min.css" type="text/css" />
  <link rel="shortcut icon" href="/css/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/css/favicon.ico" mce_href="/favicon.ico" type="image/x-icon">
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.min.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
  
  <!-- growingIO code -->
  <script type='text/javascript'>
      var _vds = _vds || [];
      window._vds = _vds;
      (function(){
        _vds.push(['setAccountId', '9f3f34627219ccd1']);
        (function() {
          var vds = document.createElement('script');
          vds.type='text/javascript';
          vds.async = true;
          vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
          var s = document.getElementsByTagName('script')[0];
          s.parentNode.insertBefore(vds, s);
        })();
      })();
  </script>
  
  <!-- 删掉 baidu spider 主动推送，无效 -->
  <!-- baidu spider initiative push -->
<!-- <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
  </script> -->
  
  <!-- google analytics push code -->
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72176628-2', 'auto');
      ga('send', 'pageview');
  </script>

</head>

<!-- meiqia plug-in -->
<!-- 
<script type='text/javascript'>
    (function(m, ei, q, i, a, j, s) {
        m[a] = m[a] || function() {
            (m[a].a = m[a].a || []).push(arguments)
        };
        j = ei.createElement(q),
            s = ei.getElementsByTagName(q)[0];
        j.async = true;
        j.charset = 'UTF-8';
        j.src = i + '?v=' + new Date().getUTCDate();
        s.parentNode.insertBefore(j, s);
    })(window, document, 'script', '//static.meiqia.com/dist/meiqia.js', '_MEIQIA');
    _MEIQIA('entId', 15857);
</script>
 -->

<body>
  <?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

   <title>Taotao's Zone</title>
   <link href="http://litaotao.github.io//atom.xml" rel="self" type="application/atom+xml"/>
   <link href="http://litaotao.github.io/" rel="alternate" type="text/html" />
   <updated>2017-01-04T14:08:48+08:00</updated>
   <id>http://litaotao.github.io/</id>
   <author>
     <name></name>
     <email></email>
   </author>

   
   <entry>
     <title>『 Spark 』14. 一次 Spark SQL 性能提升10倍的经历</title>
     <link href="/spark-sql-parquet-optimize"/>
     <updated>2016-12-13T00:00:00+08:00</updated>
     <id>/spark-sql-parquet-optimize</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本号还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。&lt;/p&gt;

&lt;p&gt;Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦；3. 点击右边目录上方的 &lt;em&gt;present mode&lt;/em&gt; 哦。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Notes&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;本篇开始，会渐渐的把版本升级到 2.0 上，后续的文章也会逐渐基于 2.0 来写；前面的文章就不改了，反正都是换汤不换药;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上一篇文章： 
&lt;a href=&quot;http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner&quot;&gt;『 Spark 』13. Spark 2.0 Release Notes 中文版 &lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 遇到了啥问题&lt;/h2&gt;

&lt;p&gt;是酱紫的，简单来说：并发执行 spark job 的时候，并发的提速很不明显。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/what_are_you_talking_about.png&quot; alt=&quot;what_are_you_talking_about.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;嗯，且听我慢慢道来，啰嗦点说，类似于我们内部有一个系统给分析师用，他们写一些 sql，在我们的 spark cluster 上跑。随着分析师越来越多，sql job 也越来越多，等待运行的时间也越来越长，我们就在想怎么把 sql 运行的时间加快一点。我们的整个架构是 spark 1.6.1 on YARN 的，经过分析一些 sql 发现其实大多数分析语句都是比较简单的统计 sql，集群资源也还算多，一条简单的 sql 语句就把整个集群资源的坑占着略显不合适，有点飞机马达装到拖拉机上的赶脚，所以第一步，我们想，支持 spark job 的并行运行。&lt;/p&gt;

&lt;p&gt;ok，初步方案有了，我们就做了如下几步改善工作：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;首先设置 &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.scheduler.mode&lt;/code&gt; 为 &lt;code class=&quot;highlighter-rouge&quot;&gt;FAIR&lt;/code&gt; 模式，首先 &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.scheduler.mode&lt;/code&gt; 有 &lt;code class=&quot;highlighter-rouge&quot;&gt;FIFO&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;FAIR&lt;/code&gt; 两种模式，&lt;code class=&quot;highlighter-rouge&quot;&gt;FIFO&lt;/code&gt; 是说提交的job，都是顺序执行的，后提交的 job 一定要等之前提交的 job 完全执行结束后才可以执行；&lt;code class=&quot;highlighter-rouge&quot;&gt;FAIR&lt;/code&gt; 是说，如果之前提交的 job 没有用完集群资源的话，后提交的job可以即刻开始运行。关于这点在官方文档上有详细的解释：&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../images/schedule_mode.png&quot; alt=&quot;schedule_mode.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;其次，我们生成了 10 个 pool，所谓的 pool，可以理解为资源池，或者通道。你可以在提交 job 的时候指定提交到哪个 pool 里面，可以简单的理解为我们把所有的集群资源分成 10 份，然后在提交 job 的时候指定在哪一份资源中运行这个 job。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../images/10_pool.png&quot; alt=&quot;10_pool.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;最后，我们在提交 job 的时候指定提交到的 pool 名字，只需要在提交 job 之前设置一个 sparkContext 的参数即可: &lt;code class=&quot;highlighter-rouge&quot;&gt;sc.setLocalProperty(&quot;spark.scheduler.pool&quot;, &quot;your_pool_id&quot;)&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../images/pool_id.png&quot; alt=&quot;pool_id.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;看似很简单，但能知道上面这些配置的也算是用 spark 比较熟练的人了吧，我迫不及待的测试了一下速度，发现了一个从古至今的大真理：理想很美好，现实很骨干啊。测试下来，发现多个 job 并行运行的时间并没有节省多少。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 原因排查&lt;/h2&gt;

&lt;p&gt;上面把问题说得很清楚了：多 job 并行的时候，运行速度并没有明显提升。但是原理上应该不会如此，只要一个 sql job 不需要全局所有集群资源，理论上来说会有较大提升的。下面是一组简单的数据对比：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/data_contrast_1.png&quot; alt=&quot;data_contrast_1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;虽然看到，并行计算后时间只需要之前的 50%，但是这里需要说明一下，这个数据不够稳定的哦，比如说偶尔会新增 10来秒 这样子的。这里 &lt;code class=&quot;highlighter-rouge&quot;&gt;暂且接受提升 50% 的速度这样一个结论吧&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;但是，理论上来说，还能提升更多，不满足 50% 的提升效率，我们接着深度解读 spark web ui 上的一些分析数据，尝试找找能否把速度再度提升一下。终于找到了核心原因，下面我就把整个排查的过程详细记录下来：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;找一个花费时间较长的 job，进去看看执行的详情，这里我们用 job id 为 796 的这个 job&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../images/spark_optimize_1.png&quot; alt=&quot;spark_optimize_1.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;发现 job 796 有两个 stage，且有 99% 的时间都花在第一个 stage 1590 上了，而且需要注意的是，这个 stage 有 237.6mb 的数据读取，有可能需要经过网络从其他 hdfs 节点读过来，难道跟网络 I/O 有关？继续点进去看看。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../images/spark_optimize_2.png&quot; alt=&quot;spark_optimize_2.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;进来这个 stage 内部，似乎发现问题所在了，首先我们先关注下图中标记的几个点，可以总结出几个点：&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;首先，该 stage 内的所有任务在 executor 上真正执行的时间【可以理解为 cpu time】是 2s&lt;/li&gt;
      &lt;li&gt;其次，该 stage 内任务执行完成的时间是 1.1 m，大概是 66s，可以理解为【wall time】&lt;/li&gt;
      &lt;li&gt;该 stage 内所有的 task，&lt;code class=&quot;highlighter-rouge&quot;&gt;schedule delay&lt;/code&gt; 的时间中位数是 0.5s，最大达到 1s【真正执行的时间也才 2s 哦】&lt;/li&gt;
      &lt;li&gt;该 stage 内一共有 336 个task&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;../images/spark_optimize_3.png&quot; alt=&quot;spark_optimize_3.png&quot; /&gt;
  &lt;img src=&quot;../images/spark_optimize_4.png&quot; alt=&quot;spark_optimize_4.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;到这里，问题根源基本上已经知道了，即 job 796 的大多数时间都被消耗在 stage 1590 的 336 个task 的 secheduler delay 上面了。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 如何解决&lt;/h2&gt;

&lt;p&gt;上面问题几乎已经明确了，现在就该看看肿么解决了。我当时是这样去考虑的：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;为什么 scheduler delay 会这么大&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;因为资源不够，要解决这个问题，似乎唯一的办法就是增加集群资源了。可是哥们，集群是你想加就能加的吗？那可是要砸钱的呀？而且如果公司缺机器的话，想加集群资源也要经过 申请-&amp;gt;审批-&amp;gt;采购-&amp;gt;分配-&amp;gt;集群配置 大大小小几个阶段，说不一定等你找到女朋友了都还没搞定啊。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当时想着加资源这个方案短期不可取后，有那么几分钟是觉得有点烧脑的。我就静静的看着 web ui，心里在算，一个 task 如果平均 scheduler delay 0.5s 的话，这 336 个 task 就得 delay 118 秒，基本上都到 2 分钟了。这 delay 的时间可真够长的啊，就在算这个数值的时候，突然想到这样一个公式：&lt;code class=&quot;highlighter-rouge&quot;&gt;total delay time = average delay time * task number&lt;/code&gt;。现在我们的问题是要解决 total delay time，那完全可以从两方面去解决呀：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;降低 average delay time：目前来看似乎唯一的方法是砸钱加资源&lt;/li&gt;
  &lt;li&gt;降低 task 数：粗略来看，简单的降低 task 数的话，应该是能减少 total delay time 的，但是如果task 数降低了，意味着每个 task 需要处理的数据量就多了，那其他的时间应该是会增加一些的，比如说 &lt;code class=&quot;highlighter-rouge&quot;&gt;Task Deserialization Time, Result Serialization Time, GC Time, Duration&lt;/code&gt; 等。减少 task 数究竟能不能提高整体运行速度，似乎乍一看还真不好确定。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;反正砸钱加资源这个方案暂时是行不通的，要不就再仔细分析一下降低task数这个方案。这里我们在仔细参考一下下图中这一列指标：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark_optimize_5.png&quot; alt=&quot;spark_optimize_5.png&quot; /&gt;
&lt;img src=&quot;../images/spark_optimize_6.png&quot; alt=&quot;spark_optimize_6.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们用 75 分位的统计数据来做一个假设：假设我们把每一个 task 的数据量加 10 倍，那么预计的 task metrics 75 分位大概是一个什么样的数值，假设这些指标都是线性增长的话：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Duration: 扩大到 10 倍，14ms&lt;/li&gt;
  &lt;li&gt;Scheduler Delay: 这个指标不用估计&lt;/li&gt;
  &lt;li&gt;Task Deserialization Time: 扩大到 10 倍，6ms&lt;/li&gt;
  &lt;li&gt;GC Time: 扩大到 10 倍，最多1ms&lt;/li&gt;
  &lt;li&gt;Result Serialization Time: 扩大到 10 倍，最多1ms&lt;/li&gt;
  &lt;li&gt;Getting Result Time: 扩大到 10 倍，最多1ms&lt;/li&gt;
  &lt;li&gt;Peak Execution Memory: 扩大到 10 倍，最多 1b&lt;/li&gt;
  &lt;li&gt;Input Size / Records: 扩大到 10 倍，918.8 KB * 2 / 2&lt;/li&gt;
  &lt;li&gt;Shuffle Write Size / Records  0: 扩大到 10 倍，294.0 B * 2/ 20&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以看到，这样大概估计下来，除去 Scheduler Delay 的时间，其实其他时间也没消耗多少，都是毫秒级的，看起来应该是完全可行的呀。&lt;/p&gt;

&lt;p&gt;正准备这样测试的时候，我忽然想到，为什么现在的 metrics 统计是这样的结构的啊，这么多 task？一般来说，一个 task 对应到 hdfs 上的一个 parquet 文件【该项目中所有数据文件都是用 parquet 压缩后存储到 hdfs 上的】，难道是现在存在 hdfs 上的 parquet 文件个数过多，每个文件太小？突然有一种恍然大悟的感觉，赶紧看看现在 hdfs 上文件的结构，如下所示：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/dyes/git-mercury/mercury-computing&lt;span class=&quot;nv&quot;&gt;$hadoop&lt;/span&gt; fs -ls -h hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ | cat -n | tail
317  -rw-r--r--   3 taotao hfmkt      1.3 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00310-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
318  -rw-r--r--   3 taotao hfmkt      1.4 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00311-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
319  -rw-r--r--   3 taotao hfmkt      2.9 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00312-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
320  -rw-r--r--   3 taotao hfmkt      1.2 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00313-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
321  -rw-r--r--   3 taotao hfmkt      1.9 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00314-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
322  -rw-r--r--   3 taotao hfmkt      1.7 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00315-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
323  -rw-r--r--   3 taotao hfmkt    899.4 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00316-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
324  -rw-r--r--   3 taotao hfmkt      2.3 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00317-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
325  -rw-r--r--   3 taotao hfmkt      1.0 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00318-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
326  -rw-r--r--   3 taotao hfmkt    460.9 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00319-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;可以看到，现在有 300 多个文件【上面只是一部分，还有十几个在另外一个文件夹里，一个 sql 会统计两个文件夹里的数据文件】，而且我仔细看了一下，每个文件大小最小的有很多 1kb 的，最大的有 2.9mb 的。难怪了，原来核心根源在这里。再结合上面关于 metrics 的分析，我心里大概确信了，只要把 parquet 文件的问题解决就行了，方法就是压缩 parquet 文件个数，控制每个 parquet 文件的大小即可。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/bingo.png&quot; alt=&quot;bingo.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;方法确定了，那就干咯。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;4. 效果对比&lt;/h2&gt;

&lt;p&gt;未来方便对比，我把 20161212 的数据文件处理了一下，保留 20161117 这天的数据文件【20161212 的数据文件整体上比 20161117 的数据文件要多 10%】，下面是对比结果：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;parquet 文件个数&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;20161117 这天&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/dyes/git-mercury/mercury-computing&lt;span class=&quot;nv&quot;&gt;$hadoop&lt;/span&gt; fs -ls -h hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_S&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; | cat -n | tail -n 5
342  -rw-r--r--   3 taotao hfmkt      1.7 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00315-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
343  -rw-r--r--   3 taotao hfmkt    899.4 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00316-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
344  -rw-r--r--   3 taotao hfmkt      2.3 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00317-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
345  -rw-r--r--   3 taotao hfmkt      1.0 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00318-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
346  -rw-r--r--   3 taotao hfmkt    460.9 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00319-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;20161212 这天&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~/Desktop/dyes/git-mercury/mercury-computing&lt;span class=&quot;nv&quot;&gt;$hadoop&lt;/span&gt; fs -ls -h hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_S&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; | cat -n | tail -n 5
34  -rw-r--r--   3 taotao hfmkt     19.2 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00013-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
35  -rw-r--r--   3 taotao hfmkt     10.7 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00014-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
36  -rw-r--r--   3 taotao hfmkt     26.0 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00015-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
37  -rw-r--r--   3 taotao hfmkt     20.1 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00016-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
38  -rw-r--r--   3 taotao hfmkt      8.7 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00017-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;100个job并发执行时间&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;20161117 这天：99s&lt;/li&gt;
  &lt;li&gt;20161212 这天：16s&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Spark Web UI 上一个 job 对比&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;20161117 这天&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark_optimize_2.png&quot; alt=&quot;spark_optimize_2.png&quot; /&gt;
&lt;img src=&quot;../images/spark_optimize_3.png&quot; alt=&quot;spark_optimize_3.png&quot; /&gt;
&lt;img src=&quot;../images/spark_optimize_4.png&quot; alt=&quot;spark_optimize_4.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;20161212 这天&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark_optimize_7.png&quot; alt=&quot;spark_optimize_7.png&quot; /&gt;
&lt;img src=&quot;../images/spark_optimize_9.png&quot; alt=&quot;spark_optimize_9.png&quot; /&gt;
&lt;img src=&quot;../images/spark_optimize_8.png&quot; alt=&quot;spark_optimize_8.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;5. 总结&lt;/h2&gt;

&lt;p&gt;首先，需要说明的是，这次优化应该还有提升的空间，虽然优化后整体从 204s 到 99s 再到 16s，提升了十倍多，确实很大，但是最后我们还是发现 16s 的情况下，scheduler delay 和 Task Deserialization Time 还是有占用了大部分时间，这里我觉得不能一味的在文件个数和大小上下功夫了。需要考虑到用户场景来做一个权衡。所以越到后期的优化，越考验产品功能的设计，当然这是后话了，就不在本文范围内讨论。&lt;/p&gt;

&lt;p&gt;其次，这次优化，从发现问题，追根溯源，到最后解决问题，大概花了 1 小时，基本上还算不错。通过这次排查，还是真心感受到 spark 设计的完善，不得不说，作为一个开源项目，spark 最大的特点，我觉得应该是 spark 是由一帮非程序员设计实现的，而是一帮由程序员，架构师，产品经理组合起来一起干的，更像是一个产品，而不是一个开源项目。怪不得这帮人要去开个公司【databricks：我最看好的公司之一】，看来真的是 born this way。说到这，不得不感触一下，对比 spark 这帮人，现实中真的有太多指令式程序员了，老板叫干嘛就干嘛，丝毫不关注产品功能，未来发展，甚至很多工程师都不用自己开发的产品。我不知道这样的人是怎么想的，反正我自己觉得这样挺可怜的。&lt;/p&gt;

&lt;p&gt;最后，好久都没写 spark 相关的文章了，距离上一片水文过去整整两个月了。最近两个月真心累成狗了，要做好项目，关注竞品的发展，行业动态；还要经常出去拜访客户，维护客户；同时也要做好产品未来几个月甚至几个季度的规划，偶尔还要搞搞运营啥的。文章写少了，但视野真心见长了，anyway，未来再接着抽空多记录点文字下来，哈哈。&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;6. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://parquet.apache.org/documentation/latest/&quot;&gt;Apache Parquet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application&quot;&gt;scheduling-within-an-application&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/configuration.html#scheduling&quot;&gt;configuration scheduling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://spark.apache.org/docs/latest/job-scheduling.html#configuring-pool-properties&quot;&gt;job-scheduling.html configuring-pool-properties&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/yurunmiao/p/5195754.html&quot;&gt;Spark使用CombineTextInputFormat缓解小文件过多导致Task数目过多的问题&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.cloudera.com/blog/2009/02/the-small-files-problem/&quot;&gt;The Small Files Problem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.databricks.com/questions/1509/parquet-file-merging-or-other-optimisation-tips.html&quot;&gt;Parquet file merging or other optimisation tips&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://spark-summit.org/2015/events/data-storage-tips-for-optimal-spark-performance/&quot;&gt;Data Storage Tips for Optimal Spark Performance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-8&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark?s=inner&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts?s=inner&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model?s=inner&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd?s=inner&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper?s=inner&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model?s=inner&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction?s=inner&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing?s=inner&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark?s=inner&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance?s=inner&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-mlib-machine-learning?s=inner&quot;&gt;『 Spark 』11. spark 机器学习&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-2.0-faster-easier-smarter?s=inner&quot;&gt;『 Spark 』12. Spark 2.0 特性介绍&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner&quot;&gt;『 Spark 』13. Spark 2.0 Release Notes 中文版 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-sql-parquet-optimize?s=inner&quot;&gt;『 Spark 』14. 一次 Spark SQL 性能优化之旅&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 读书笔记 』9月，10月读书总结｜博文推荐</title>
     <link href="/books-recommend-and-summarize-on-sep-2016"/>
     <updated>2016-12-05T00:00:00+08:00</updated>
     <id>/books-recommend-and-summarize-on-sep-2016</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;计划是每月读 5-10 本书，书籍类型大概是三个方面的：金融，技术，创业。之所以选择这三个方面，一方面是因为自己对这三个方面都很有兴趣，其次是被 linkedin 创始人 Hoffman 的 &lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;ABZ 理论&lt;/a&gt; 深度影响。建议大家都看看 abz 理论那篇文章，如果我有空，也会整理一些常用的这类理论模型到博客里的。&lt;/p&gt;

&lt;p&gt;月底读书总结的形式都很简单，只是简单的一个列表和简单的书评，对觉得比较好的书会有单独的读书笔记。另外推荐大家用 excel 来做一些简单的工作管理，我现在就用 google docs 来做工作安排和读书计划，个人感觉比一些常用的神马协同软件强大太多了，简单，够用，就行了。工作中见过太多人把时间都花到使用那些协同软件上去，不得不说避重就轻了，适得其反，哈哈。&lt;/p&gt;

&lt;p&gt;下面是一张我用 google docs 来做本月读书安排的截图，不同颜色代表不同类别的数据，清晰明了实用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/books_9_10.png&quot; alt=&quot;books_9_10.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ps: 我对好书的定  义很简单：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给自己有所启发的&lt;/li&gt;
  &lt;li&gt;高质量的，专业的教程类书籍&lt;/li&gt;
  &lt;li&gt;后期会再度回首的书&lt;/li&gt;
  &lt;li&gt;看完后会打算赠送给盆友看的书&lt;/li&gt;
  &lt;li&gt;留着给儿子看的书 [好吧，目前我只有个宝贝侄儿，哈哈]&lt;/li&gt;
  &lt;li&gt;最后一条，印刷质量要好&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上月读书总结：&lt;a href=&quot;../books-recommend-and-summarize-on-july-2016&quot;&gt;『 读书笔记 』坚持读书 6 个多月的感受&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 读书总结&lt;/h2&gt;

&lt;h3 id=&quot;section-2&quot;&gt;1.1 公司财务原理，第七，八章&lt;/h3&gt;

&lt;p&gt;这本书越来越有意思了，曾经听一个朋友说这本书就是讲一些公司财务的东西，看来是顾名思义去了吧。其实就跟我第一次总结的一样，这本书从小来说，能让你了解公司财务，金融市场运作的一些情况，对从事投资方面的人来说很有用；从大来说，这本书能交给你不少关于如何开展，运作一个公司的很多规则和经验，非常有用。严重推荐，值得认真研读。&lt;/p&gt;

&lt;p&gt;比如说，第七，八章就没有讲什么公司财务的东西了，而是讲一些风险，资产定价相关的东西，非常有用。&lt;/p&gt;

&lt;p&gt;总结：这本书什么都好，除了原版的太贵了，我看的是第十版原版的打印版，100多，黑白色的；原版印刷版的是彩色版的，死贵了，但是看起来真是贼爽。我有时候都是电子版的印刷版结合黑白色的打印版一起来看的。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;下面是一张原版印刷版的电子截图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/amazing_book.png&quot; alt=&quot;amazing_book.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne680aae8af9ee8a18ce4b8bae5ada6-e58fafe9a284e6b58be79a84e99d9ee79086e680a7-e4b8b9e280a2e889bee7919ee9878cdpb0040no84wrefsr11ieutf8qid1478565337sr8-1keywordse680aae8af9ee8a18ce4b8bae5ada6&quot;&gt;1.2 &lt;a href=&quot;https://www.amazon.cn/%E6%80%AA%E8%AF%9E%E8%A1%8C%E4%B8%BA%E5%AD%A6-%E5%8F%AF%E9%A2%84%E6%B5%8B%E7%9A%84%E9%9D%9E%E7%90%86%E6%80%A7-%E4%B8%B9%E2%80%A2%E8%89%BE%E7%91%9E%E9%87%8C/dp/B0040NO84W/ref=sr_1_1?ie=UTF8&amp;amp;qid=1478565337&amp;amp;sr=8-1&amp;amp;keywords=%E6%80%AA%E8%AF%9E%E8%A1%8C%E4%B8%BA%E5%AD%A6&quot;&gt;怪诞行为学&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;以前大学的时候就浏览过这本书，当时就觉得非常有意思。如今再次品读，更有一番韵味啊。现在市场上还有其他几本非常相似的书，比如说《怪诞行为学2》，《怪诞经济学》，《怪诞心理学》什么的。虽然我觉得先品读一本就够了，把其中的道理领悟就够了。但是我也准备后期抽时间读读其他类型的书，看看是否能找到一些更好玩的东西。&lt;/p&gt;

&lt;p&gt;总结：很有意思的一本书。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne8afb4e8b08ee88085e79a84e68991e5858be7898c-e58d8ee5b094e8a197e79a84e68a95e8b584e6b8b8e6888f-e8bf88e5858be5b094e280a2e58898e69893e696afdpb00dyrvnjsrefsr11ieutf8qid1478565669sr8-1keywordse8afb4e8b08ee88085e79a84e68991e5858be7898c&quot;&gt;1.3 &lt;a href=&quot;https://www.amazon.cn/%E8%AF%B4%E8%B0%8E%E8%80%85%E7%9A%84%E6%89%91%E5%85%8B%E7%89%8C-%E5%8D%8E%E5%B0%94%E8%A1%97%E7%9A%84%E6%8A%95%E8%B5%84%E6%B8%B8%E6%88%8F-%E8%BF%88%E5%85%8B%E5%B0%94%E2%80%A2%E5%88%98%E6%98%93%E6%96%AF/dp/B00DYRVNJS/ref=sr_1_1?ie=UTF8&amp;amp;qid=1478565669&amp;amp;sr=8-1&amp;amp;keywords=%E8%AF%B4%E8%B0%8E%E8%80%85%E7%9A%84%E6%89%91%E5%85%8B%E7%89%8C&quot;&gt;说谎者的扑克牌&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书是从一个曾在所罗门任职的交易员角度，讲了一些在过去几十年里华尔街的一些变化和华尔街人的各种状态。可能是中文翻译的问题，有些地方读起来感觉很干涩。下次读作者的另外一本出名作《大空头》的时候，准备看看原版的了。&lt;/p&gt;

&lt;p&gt;总结：还行吧，如果想了解华尔街以及上世纪华尔街人的一些心理转变的话，可以去看看。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;uwsgi-documenthttpsuwsgi-docsreadthedocsioenlatest&quot;&gt;1.4 &lt;a href=&quot;https://uwsgi-docs.readthedocs.io/en/latest/&quot;&gt;uwsgi document&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这是 uwsgi 的官方文档，因为之前用 uwsgi 发现一些问题，所以准备系统的看看官方文档。虽然 uwsgi 的文档有的地方写得很简单，不好理解，官方也没有例子来讲解，但是看了之后还是收获多多的。&lt;/p&gt;

&lt;p&gt;总结：新手可以直接 copy 别人的 uwsgi 配置文件就行了，要是想升级一下自己的话，推荐多仔细读读相关官方文档。对于那些随便 copy 别人的代码，然后出了问题第一时间就是去 &lt;code class=&quot;highlighter-rouge&quot;&gt;请教&lt;/code&gt; 的人，哥一向是懒得理的。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;gunicorn-documenthttpdocsgunicornorgenlatestinstrumentationhtml&quot;&gt;1.5 &lt;a href=&quot;http://docs.gunicorn.org/en/latest/instrumentation.html&quot;&gt;gunicorn document&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;之所以看了 uwsgi 的文档，还想看 gunicorn 的文档，有以下几个原因：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;我们的项目里用的是 uwsgi，但是听说 gunicorn 也非常厉害，所以也想看看 gunicorn 的肌肉；&lt;/li&gt;
  &lt;li&gt;看 uwsgi 的文档的时候，发现有的地方写得非常简洁到难懂，所以准备看看 gunicorn 的文档，如果 gunicorn 的文档比较 nice 的话，后期的项目可以考虑试试 gunicorn；&lt;/li&gt;
  &lt;li&gt;uwsgi 的源代码是用 c 写的，gunicorn 的源代码是用 python 写的，相对来说 gunicorn 的源代码更好读【当然我不是推荐什么东西都去读源代码，除非必要的时候】&lt;/li&gt;
  &lt;li&gt;uwsgi 的时间比较长了，gunicorn 比较年轻，我都喜欢比较年轻的东西，因为一般来说越新的东西在设计之初都会考虑得更全面一些，都会吸收一下前辈们的经验；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总结：gunicorn 的文档相对于 uwsgi 来说是好了一些，但也不是事无巨细，更多情况下还是需要自己多去尝试和google。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;scala-schoolhttpstwittergithubioscalaschoolzhcnindexhtml&quot;&gt;1.6 &lt;a href=&quot;https://twitter.github.io/scala_school/zh_cn/index.html&quot;&gt;scala school&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;最近想学学 scala，于是找到了 twitter 出的这个在线 scala 教程，个人觉得虽然不错，但似乎不太合我自己的口味，准备换一本书系统的读读。&lt;/p&gt;

&lt;p&gt;总结：我相信 twitter 出的教程，可能是自己水土不服吧，哈哈，准备看看 《快学 scala》肿么样。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne4b880e79c8be5b0b1e68782e79a84e696b0e585ace58fb8e5bc80e58a9ee585a8e59bbee8a7a3-e69da8e5b08fe4b8bddpb01g8jlk9grefsr11sbooksieutf8qid1479100767sr1-1keywordse4b880e79c8be5b0b1e68782e79a84e696b0e585ace58fb8e5bc80e58a9ee585a8e59bbee8a7a3&quot;&gt;1.7 &lt;a href=&quot;https://www.amazon.cn/%E4%B8%80%E7%9C%8B%E5%B0%B1%E6%87%82%E7%9A%84%E6%96%B0%E5%85%AC%E5%8F%B8%E5%BC%80%E5%8A%9E%E5%85%A8%E5%9B%BE%E8%A7%A3-%E6%9D%A8%E5%B0%8F%E4%B8%BD/dp/B01G8JLK9G/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1479100767&amp;amp;sr=1-1&amp;amp;keywords=%E4%B8%80%E7%9C%8B%E5%B0%B1%E6%87%82%E7%9A%84%E6%96%B0%E5%85%AC%E5%8F%B8%E5%BC%80%E5%8A%9E%E5%85%A8%E5%9B%BE%E8%A7%A3&quot;&gt;一看就懂的新公司开办全图解&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;最近买了一套创业的大白书来看，这是其中一本。首先内容上来说，对我这种大白真的是够用了，当然政策一直在变，也许到自己真正创业的时候，很多东西都会不一样了。但是我一贯的看法是：万变不离其宗。就算规则，政策变了，只要自己掌握一些标准的流程怎么走，到时候直接电话去相关机构问就行了，再怎么说也不会无头苍蝇乱撞。再说说看完后的感受，尼玛就是8个字：想开个公司真心难。一系列的开公司前的准备，过程中要办那么多证件，开完后要考虑招人，财务等等。关键最后还看到公司所得税那部分，尼玛居然要 25% 的所得税，这下终于知道为啥有辣么多公司要逃税漏税了，这赋税真心太重了啊。以后自己要是开公司了，一定找几个学税法的同学想想怎么 &lt;code class=&quot;highlighter-rouge&quot;&gt;交税&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;总结：本书对大白挺有用的，但是要注意的是，本书只是介绍一般开公司的一些流程，具体到你准备去干的时候，尽量先电话问清楚相关机构，要是能找到有过这方面的经验的人就更好了。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;best-python-problems-on-stackoverflowhttpstackoverflowcomquestionstaggedpython&quot;&gt;1.8 &lt;a href=&quot;http://stackoverflow.com/questions/tagged/python&quot;&gt;Best Python Problems on Stackoverflow&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;都说想要了解一座城，最好的方法就是去走走。我认为要想深入了解一门语言，除了读书，实践，更好的方法是去社区看看，看看大家在这门语言上都遇到过哪些问题，以及怎样去解决这些问题的。所以我整理了一些我觉得比较有意义的问题，在这篇文章中，不间断更新。&lt;/p&gt;

&lt;p&gt;总结：刀不磨，不会快。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;1.9 &lt;a href=&quot;&quot;&gt;超简交易：交易高手速成手册&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这是在 &lt;code class=&quot;highlighter-rouge&quot;&gt;超简交易&lt;/code&gt; 这个公众号整理的一本电子书，全书有将近 400 页，内容整理得还是非常好的。之前原本打算把这个公众号的一些文章整理来系统的看看，后来居然出了本电子书，不得不赞一下。本书内容还行，着重讲概念，例子也很仔细，可以粗看一遍，在后期应用的时候再回来细读，遇到再细节的问题的时候，就可以查查其他书籍了。&lt;/p&gt;

&lt;p&gt;总结：只能说感谢，电子书做得挺仔细的，非常好。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne98791e89e8de5b882e59cbae4b88ee98791e89e8de69cbae69e84-e5bc97e99bb7e5beb7e9878ce5858b-s-e7b1b3e4bb80e98791-e696afe59da6e588a9-g-e59f83e98791e696af-e89197dpb00ufdw1ae&quot;&gt;1.10 &lt;a href=&quot;https://www.amazon.cn/%E9%87%91%E8%9E%8D%E5%B8%82%E5%9C%BA%E4%B8%8E%E9%87%91%E8%9E%8D%E6%9C%BA%E6%9E%84-%E5%BC%97%E9%9B%B7%E5%BE%B7%E9%87%8C%E5%85%8B-S-%E7%B1%B3%E4%BB%80%E9%87%91-%E6%96%AF%E5%9D%A6%E5%88%A9-G-%E5%9F%83%E9%87%91%E6%96%AF-%E8%91%97/dp/B00UFDW1AE&quot;&gt;金融市场与金融机构（原书第7版） (华章教材经典译丛) 第1，2，3章&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书是配合 coursera 上的课程 &lt;a href=&quot;https://www.coursera.org/learn/financial-markets/home/info&quot;&gt;Basic Principles of Finance and Risk Management&lt;/a&gt; 来看的。目前这门课程我的安排是每个月上 3～4 个 week，然后再配合看 &lt;a href=&quot;&quot;&gt;金融市场与金融机构&lt;/a&gt; 这本书的一些章节。首先需要明确的是，这本书和 coursera 上的课程并不是完全匹配的，但是都是讲金融市场和金融机构的，coursera 上的相对要讲得简单一点，毕竟是网络课程，看这本书可以更加深入，系统的了解相关知识。此外，我是看 kindle 版本的，质量确实很好，书的内容本身也写得非常好。&lt;/p&gt;

&lt;p&gt;总结：非常好的一本书，可以系统的了解金融市场和金融机构的东西。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne9878fe58c96e68a95e8b584-e7ad96e795a5e4b88ee68a80e69caf-e4b881e9b98fdpb00ff1y1ekrefsr11ieutf8qid1480381034sr8-1keywordse9878fe58c96e68a95e8b584e28094e7ad96e795a5e4b88ee68a80e69caf&quot;&gt;1.11 &lt;a href=&quot;https://www.amazon.cn/%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84-%E7%AD%96%E7%95%A5%E4%B8%8E%E6%8A%80%E6%9C%AF-%E4%B8%81%E9%B9%8F/dp/B00FF1Y1EK/ref=sr_1_1?ie=UTF8&amp;amp;qid=1480381034&amp;amp;sr=8-1&amp;amp;keywords=%E9%87%8F%E5%8C%96%E6%8A%95%E8%B5%84%E2%80%94%E7%AD%96%E7%95%A5%E4%B8%8E%E6%8A%80%E6%9C%AF&quot;&gt;量化投资—策略与技术&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这个月也把丁鹏的这本书给看了，网上关于这本书的讨论很多，有喷的，有喷的，还有喷的。就我个人来看，我确实承认这本书里面的内容有的地方也许有一些问题，但是还不至于到大家所说的那个地步，当然我也不相信丁鹏所说的他自己的那个 d-alpha 系统了。原因很简单，这本书目前应该就卖出7500本左右。假设后期又加印了，那比如说卖出了 10000 本，每本定价 99 元，那总共也才卖了 99w，一般写书稿费有按页数算的，也有按销量提成的。如果按照最高提成【20%左右】来算的话，写这本书也才能赚个 99w * 20%，20w 左右。乍看起来还不错，可是自己想想，如果你自己真有这么多好的投资系统和策略，赚这 20w 不是轻轻松松的吗？干嘛还要写书呢【当然如果花个万儿八千雇个大学生当枪手就不一定了，哈哈】。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/dingpeng_books.png&quot; alt=&quot;dingpeng_books.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面只是简单的一个分析，言归正传。这本书内容上我觉得还是不错的，至少不会是看了之后还会有所收获的。其实每本书都有自己的优缺点，别老抱着看完一本书，搞定一个行业的心态去看。&lt;/p&gt;

&lt;p&gt;总结：每本书就跟每个人一样，都有自己的优缺点；看书如待人，水至清则无鱼嘛。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;2. 看片儿&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ted.com/talks/bettina_warburg_how_the_blockchain_will_radically_transform_the_economy&quot;&gt;How the blockchain will radically transform the economy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;泡沫吹吧吹吧不是罪。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=w4RLfVxTGH4&quot;&gt;Why you think you’re right – even if you’re wrong Julia Galef&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;你说的我们都懂，可是臣妾做不到啊。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=CX_Krxq5eUI&quot;&gt;Jonas Eliasson: How to solve traffic jams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;最近看的几个 ted 质量都好低啊，ted 不会也要越做越差了吧。还是看看之前的 ted 吧。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NzA1MTcyMA==&amp;amp;mid=2651162338&amp;amp;idx=1&amp;amp;sn=6d1f5a45dbbf722d8afcc2ad7bfe01c2&amp;amp;chksm=bd2ecac58a5943d3b2f5da754896fbd39d9bd5b27e76386166462d5bd1f807622fd53f4ac3ca&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1124M6cbvvyzoshOwQckj8K0&amp;amp;key=9ed31d4918c154c803f3f803618c1e3615abd26ecec3abd5b0b0e0af160a7aca3e9019bcd7ce8801e1d6ba867930111a&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=bCi8Vd6N3xy1rQ3QvUJZ%2FhFC39d4n2lnpUnSPAKHQoiJFIscVimSdhmQiGdBRmMg&quot;&gt;台湾最新走心广告：致25岁还一无是处的你！&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=CyElHdaqkjo&quot;&gt;How to raise successful kids – without over-parenting Julie Lythcott-Haims&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;终于看到一个非常不错的 TED 了，主讲人真是太有激情了，哈哈。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Ks-_Mh1QhMc&quot;&gt;Your body language shapes who you are Amy Cuddy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;非常非常非常赞的一个 talk，主讲人也超有魅力的哦。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-5&quot;&gt;3. 博文推荐&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA5MDAxMjcwOQ==&amp;amp;mid=2447614867&amp;amp;idx=1&amp;amp;sn=43059c321ee677439178f5d034343528&amp;amp;chksm=84052ed9b372a7cfde9abf42516e3916c601febb4b3e79cd4edec4a2eee625119ad14d9d7667&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=101113deGruE0jtN53Y4NSMy&amp;amp;key=c50f8b988e61749a567ba477763007f4301bfaff3d7790f6ebe4d3f8ced508919dc8c96eda38bbb62d63bfd8c073e283&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=DcoELySNvbXVGG7G%2BfzkWJ2yAN%2BDritBJteCurcvOPD4pmdqdOdBdRT%2Bjw59klVv&quot;&gt;吴军博士硅谷第一封来信：不做伪工作者&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/20259295/answer/125138094?from=timeline&amp;amp;isappinstalled=0&quot;&gt;程序员怎么升职？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA5MzA2OTczMg==&amp;amp;mid=2650874597&amp;amp;idx=1&amp;amp;sn=c2bc3ba62503dbb6bdf1be5fd4813daf&amp;amp;chksm=8b960a2ebce183381b9ef6375c5a170373766a6365eec16ba42e2c2c77162582571a5649baaa&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1011epbrL0yhQDPwQSvrQxlU&amp;amp;key=502b9ab53198616f06e7f6bbcc0f86eb13be7ac16a8c45cf3b3d314f5aedd83b05955fe4cdccfc13ca26e92f1e277b90&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=WRIhMgloARtS0w69StWALDUe0ZPHP9Gs7XsWyH%2BXSEYKO9t2RbqJlyJqDL7x2BQd&quot;&gt;他用2年时间，把中国34个省市名字重新设计一遍，无意间惊艳了超500万网友&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;此等人才，只可遇不可求啊。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/BYRans/p/5945667.html&quot;&gt;Spark存储管理（读书笔记）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://36kr.com/p/5053161.html&quot;&gt;【行研】投资交给机器，数字化投顾进场金融投资——FinTech 细分领域研究报告&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzI5MzExNDgxMw==&amp;amp;mid=2650615197&amp;amp;idx=1&amp;amp;sn=04c87d67056d1ea1ce0f4e2a37a648d0&amp;amp;chksm=f47e8b4fc30902599390f34117f42573a6c7dfa97dc4c83027c65f49c5b56b6fd9e144eaaead&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1008DemxxOKbHLURwCH1WY1b&amp;amp;key=502b9ab53198616f03c012e26b2e40df027b17064e11d483a2777eb7b74e52228024e89ad87689abb227e9db3e757ecb&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=WRIhMgloARtS0w69StWALDUe0ZPHP9Gs7XsWyH%2BXSEYKO9t2RbqJlyJqDL7x2BQd&quot;&gt;庄辰超：回顾去哪儿的这些年，最让我骄傲的是收获了这9点管理心得&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;部分思想可能有些许激进，不过万事都讲究一个度，控制好度就是最好的。毕竟物极必反。&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NTE1MDEwNQ==&amp;amp;mid=2670931644&amp;amp;idx=1&amp;amp;sn=53b9d17b3fd55d195e36a965dbfa27c9&amp;amp;chksm=851bde4ab26c575c10a3deff6c00f39df781c93e524a6db7589e6a50fc596401b52136359584&amp;amp;scene=0&amp;amp;key=502b9ab53198616f0d3c97b30212bb47ec8ca1eac1d99e2bfec8b83fddbeba828a84f210444606f392604add91a43a2e&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=WRIhMgloARtS0w69StWALDUe0ZPHP9Gs7XsWyH%2BXSEYKO9t2RbqJlyJqDL7x2BQd&quot;&gt;世界经济危机简史（1788-2000年）上&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NTE1MDEwNQ==&amp;amp;mid=2670931646&amp;amp;idx=1&amp;amp;sn=5d8c001e20c4d9639f9d801f2a99b7c0&amp;amp;chksm=851bde48b26c575e5654a8a2cc749cf2beb60615ac226ca437ecc3414f3c4e211d59ad4624cf&amp;amp;scene=0&amp;amp;key=502b9ab53198616fac715cfd89d4cd684b2e7b345114e400e6054baa39781b03ebd11f0bf6113e49c9355fc5d9c88498&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=WRIhMgloARtS0w69StWALDUe0ZPHP9Gs7XsWyH%2BXSEYKO9t2RbqJlyJqDL7x2BQd&quot;&gt;世界经济危机简史（1788-2000年）中&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NTE1MDEwNQ==&amp;amp;mid=2670931648&amp;amp;idx=1&amp;amp;sn=6d4edb5a0c75642da4ba54f77a570cae&amp;amp;chksm=851bde36b26c5720ef0068e280fd1594fbcab3e096d52953791e699646974e1f526a04992237&amp;amp;scene=0&amp;amp;key=502b9ab53198616f7fc0cba7403f81d680e173245096ee9887a85dc0c155d23f6d4856cec826a8fa8282608ebc62555b&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=WRIhMgloARtS0w69StWALDUe0ZPHP9Gs7XsWyH%2BXSEYKO9t2RbqJlyJqDL7x2BQd&quot;&gt;世界经济危机简史（1788-2000年）下&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/51043149/answer/124226744?from=timeline&amp;amp;isappinstalled=1&quot;&gt;如何看待人民日报微信公众号评论员文章称“失去奋斗，房产再多我们也将无家可归”？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://tech.glowing.com/cn/python-profiling/&quot;&gt;python-profiling&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;美国大选相关文章
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzAwMDM3MDMzMw==&amp;amp;mid=2653401652&amp;amp;idx=3&amp;amp;sn=8a9d1c8ec5546cf6302d9d8c25bfe086&amp;amp;chksm=813ae1c6b64d68d081daa18c144ce65a36e3e4ff99b8f64498ee524bb4ad3b533586567367c2&amp;amp;mpshare=1&amp;amp;scene=24&amp;amp;srcid=1109XDQ8Fo3maRU70G6wf9gw&amp;amp;key=cde9f53f8128acbd003fca83f5489233847f944ff89780143691705703b736752e4857dc15569191772a91deadb54eed&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=RORT6loaK1Xc4EjCOnHYqUceRy%2B%2BlElIjia0Fib85PVuxJJHTMhLibyFBjQh1eZP&quot;&gt;一文看懂美国大选如何影响资本市场&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA5NTIwODMwNw==&amp;amp;mid=2651065084&amp;amp;idx=1&amp;amp;sn=12d43a2da6b9bbc140386ea9c34a24ef&amp;amp;chksm=8bb27ce0bcc5f5f6fc49a12c7a49e4e62be7daae1b3264e999404d7e5b7e169d3517682b10e4&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1108CyI6BqpWc1g7Zy54Q1EB&amp;amp;key=cde9f53f8128acbda646f6570b118a6148427df939b41baaf7541ff0194cfec036eca77a2648dba43be7c1a5fc069714&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=RORT6loaK1Xc4EjCOnHYqUceRy%2B%2BlElIjia0Fib85PVuxJJHTMhLibyFBjQh1eZP&quot;&gt;2016美国大选：一场没有赢家的闹剧&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NjMxNzgyMw==&amp;amp;mid=2653435388&amp;amp;idx=3&amp;amp;sn=488a71d37b752805280efadbd8972731&amp;amp;chksm=bd378aec8a4003fab65ecfdbcdc24fb17bf0b3dac4343ecfc5afd1b49c36860184caf4126d66&amp;amp;mpshare=1&amp;amp;scene=24&amp;amp;srcid=11096hitz6125QsGqyrU4P52&amp;amp;key=cde9f53f8128acbd33694411c38620a13df771d355888d655cb0473d24ad3747c8dbaaf8f6aec7701fe1d91016bb1a29&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=RORT6loaK1Xc4EjCOnHYqUceRy%2B%2BlElIjia0Fib85PVuxJJHTMhLibyFBjQh1eZP&quot;&gt;美国大选要点须知及对市场影响简评&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://baike.baidu.com/view/1408004.htm&quot;&gt;美国总统选举制度&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIyMTA4ODYyNA==&amp;amp;mid=2649715482&amp;amp;idx=1&amp;amp;sn=d0478c4e56b50ee9bfd1937fcd166081&amp;amp;chksm=8fd9cd05b8ae4413a1aa0bf6d9097a7948de0325135827c8e961b0b80c320937b23e067914bc&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1106mly9lHyuMJ6bO1i1KMgI&amp;amp;key=cde9f53f8128acbdf3d894562ee4fe0880d20a102a83885bf1e7294fa629678b6b76b5f00d00f75761bba162eecc4447&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=RORT6loaK1Xc4EjCOnHYqUceRy%2B%2BlElIjia0Fib85PVuxJJHTMhLibyFBjQh1eZP&quot;&gt;创业公司如何选大将？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NTE1MDEwNQ==&amp;amp;mid=2670933077&amp;amp;idx=3&amp;amp;sn=be565ce308f378989c94636d266dd1bf&amp;amp;chksm=851bc4a3b26c4db5f3ded8a813917a8088ef6e4bad551c469d5822de3c1ab5f883c68be6e5d5&amp;amp;scene=0&amp;amp;key=cde9f53f8128acbdc93e02c39973ec8a03709ba9d4a9b14ff416552e07876255194bb86f2e8f4b8005a16e3fe9a17761&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=RORT6loaK1Xc4EjCOnHYqUceRy%2B%2BlElIjia0Fib85PVuxJJHTMhLibyFBjQh1eZP&quot;&gt;中国量化对冲策略及产品的全解读&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2650994876&amp;amp;idx=1&amp;amp;sn=17b2575797089374b64d5ebe10107ff8&amp;amp;chksm=bdbf00ef8ac889f9c4eb10a28babdd97ac0127cb2fa034b7574c804610ad94f6e8db208d7c21&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1123UbXpWwwT74CzhkH1vuQQ&amp;amp;key=9ed31d4918c154c8d05e34f6e450b1cfbf8a88cb97c4a8211690dc6c43cc95ca25441d0156984bd13944f23ad5339160&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=bCi8Vd6N3xy1rQ3QvUJZ%2FhFC39d4n2lnpUnSPAKHQoiJFIscVimSdhmQiGdBRmMg&quot;&gt;Hadoop、Spark等5种大数据框架对比，你的项目该用哪种？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/88301/&quot;&gt;学习笔记：The Log（我所读过的最好的一篇分布式技术文章）&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying&quot;&gt;The Log: What every software engineer should know about real-time data’s unifying abstraction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NDAxODg4OA==&amp;amp;mid=2651081540&amp;amp;idx=2&amp;amp;sn=7b9a93d2e88e999b5d293d88346011b5&amp;amp;chksm=841d78e3b36af1f569a53c85215c58b354cfa9534d1be66928262b46a6918fde5d80f87e8061&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1120g9rq2Yy4WIqIBVtshcph&amp;amp;key=9ed31d4918c154c89f8f3387a3f995fa6830b43640657bee99ff431268cfea4cb773f8781b361e5de894dadd1773a1c3&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=bCi8Vd6N3xy1rQ3QvUJZ%2FhFC39d4n2lnpUnSPAKHQoiJFIscVimSdhmQiGdBRmMg&quot;&gt;18岁的希拉里，清纯的本拉登，跑龙套的成龙….这是朋友圈里最珍贵的照片！&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDI3MjA5MQ==&amp;amp;mid=2697265591&amp;amp;idx=1&amp;amp;sn=48cd5869b3b1bbcfa9e22b77016e355d&amp;amp;chksm=8376fe83b401779588f1837371c0d85307a1e998f357292fa3a8ce89be402060c2fdbe53bc66&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=1115NMJMrArj8mMveoifQjqA&amp;amp;key=9ed31d4918c154c894345cb930ce69ce1ffd239c54f37bca2a9c3eb84e998cfe4c88940dc3a9394d968bdaa90f131305&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=bCi8Vd6N3xy1rQ3QvUJZ%2FhFC39d4n2lnpUnSPAKHQoiJFIscVimSdhmQiGdBRmMg&quot;&gt;干货 Tomcat类加载机制触发的Too many open files问题分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.linkedin.com/pulse/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%B8%8D%E9%80%89%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%80-tony-qu-%E7%9E%BF%E6%9D%B0&quot;&gt;为什么我不选阿里云&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjAzNzMzNTkyMQ==&amp;amp;mid=2653749588&amp;amp;idx=1&amp;amp;sn=79ad8e0c2b5c1cc2589f4129b2bc3a72&amp;amp;mpshare=1&amp;amp;scene=2&amp;amp;srcid=0601zOCo3bZcUqls5mBR6pKb&amp;amp;key=9ed31d4918c154c85f757691915e1fcab822a9b6b9b563d18b44215d2f68316b69d13bafc1c15bb0a181f2fd1f4b1d0d61c226f712f447335804b2aa685f7d382bb4cc217bf35efdc32ccf80386b5ee1&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=bXG1GuJH%2BKx%2BzbE5O8r1mz3TVQ1IN2GwY6aPL%2Fj1j9uSquqW2pdBpLukNMb7qXpo&quot;&gt;从价值1300亿美元到40亿都没人要，这桩互联网惊天惨案是怎么诞生的？&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;居安思危啊。有时候你的成功，并不是因为你自己才成功的，也许是运气刚好而已吧。最近很流行一句话 “离开了公司，大多数人什么都不是”，共勉。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NTIyMjgwNw==&amp;amp;mid=2650654204&amp;amp;idx=1&amp;amp;sn=5ba0dca6ba06514fc70dc49cf728c393&amp;amp;chksm=87d25104b0a5d812b88f56016b70e9d0899bfb48d9bf18fd5d7ccb9c22e070ca9e01e712e6f1&amp;amp;scene=0&amp;amp;key=9ed31d4918c154c8b561fd4c209a1c38d82df894f5253bd0c3bfadf950d2f912faa7a21f3fc28a958e1469418874432871b81812ec703b8444ac15e1d3e82a5a40f967c797fa7ea2221c2c1923cf0266&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.12+build(16A323)&amp;amp;version=11020201&amp;amp;pass_ticket=bXG1GuJH%2BKx%2BzbE5O8r1mz3TVQ1IN2GwY6aPL%2Fj1j9uSquqW2pdBpLukNMb7qXpo&quot;&gt;大盘上涨趋势已经确立&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;留富兵法周报挺不错的，尝试自己实现到策略里看看。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-6&quot;&gt;4. 优质产品&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://coggle.it/&quot;&gt;https://coggle.it/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;优质在线思维导图。&lt;/p&gt;

&lt;h2 id=&quot;section-7&quot;&gt;5. 读书总结系列&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-mar-2016&quot;&gt;『 读书笔记 』3月读书总结和推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-apr-2016&quot;&gt;『 读书笔记 』4月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-May-2016&quot;&gt;『 读书笔记 』5月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-June-2016&quot;&gt;『 读书笔记 』6月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-july-2016&quot;&gt;『 读书笔记 』坚持读书 6 个多月的感受&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-sep-2016&quot;&gt;『 读书笔记 』9月，10月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>Best Python Problems on Stackoverflow</title>
     <link href="/python-stackoverflow-question"/>
     <updated>2016-11-11T00:00:00+08:00</updated>
     <id>/python-stackoverflow-question</id>
     <content type="html">&lt;h2 id=&quot;python-stackoverflow-&quot;&gt;Python Stackoverflow 经典问题&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do&quot;&gt;What does the “yield” keyword do?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python&quot;&gt;What is a metaclass in Python?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists-using-python&quot;&gt;How do I check whether a file exists using Python?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/394809/does-python-have-a-ternary-conditional-operator&quot;&gt;Does Python have a ternary conditional operator?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/89228/calling-an-external-command-in-python&quot;&gt;Calling an external command in Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/419163/what-does-if-name-main-do&quot;&gt;What does &lt;code class=&quot;highlighter-rouge&quot;&gt;if __name__ == “__main__”:&lt;/code&gt; do?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/739654/how-to-make-a-chain-of-function-decorators-in-python&quot;&gt;How to make a chain of function decorators in Python?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value&quot;&gt;Sort a Python dictionary by value&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/273192/how-to-check-if-a-directory-exists-and-create-it-if-necessary&quot;&gt;How to check if a directory exists and create it if necessary?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod-in-python&quot;&gt;What is the difference between @staticmethod and @classmethod in Python?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference&quot;&gt;How do I pass a variable by reference?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/101268/hidden-features-of-python&quot;&gt;Hidden features of Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/1436703/difference-between-str-and-repr-in-python&quot;&gt;Difference between &lt;strong&gt;str&lt;/strong&gt; and &lt;strong&gt;repr&lt;/strong&gt; in Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/509211/explain-pythons-slice-notation&quot;&gt;Explain Python’s slice notation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods&quot;&gt;Understanding Python super() with &lt;strong&gt;init&lt;/strong&gt;() methods&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/123198/how-do-i-copy-a-file-in-python&quot;&gt;How do I copy a file in python?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/36901/what-does-double-star-and-star-do-for-parameters&quot;&gt;What does ** (double star) and * (star) do for parameters?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/30081275/why-is-1000000000000000-in-range1000000000000001-so-fast-in-python-3&quot;&gt;Why is “1000000000000000 in range(1000000000000001)” so fast in Python 3?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/3061/calling-a-function-of-a-module-from-a-string-with-the-functions-name-in-python&quot;&gt;Calling a function of a module from a string with the function’s name in Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/931092/reverse-a-string-in-python&quot;&gt;Reverse a string in Python&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/582336/how-can-you-profile-a-python-script&quot;&gt;How can you profile a Python script?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;&quot;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>『 Spark 』13. Spark 2.0 Release Notes 中文版</title>
     <link href="/spark-2.0-release-notes-zh"/>
     <updated>2016-09-13T00:00:00+08:00</updated>
     <id>/spark-2.0-release-notes-zh</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本号还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。&lt;/p&gt;

&lt;p&gt;Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦；3. 点击右边目录上方的 &lt;em&gt;present mode&lt;/em&gt; 哦。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Notes&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;本篇开始，会渐渐的把版本升级到 2.0 上，后续的文章也会逐渐基于 2.0 来写；前面的文章就不改了，反正都是换汤不换药;&lt;/li&gt;
  &lt;li&gt;本篇是上一篇文章的升级版，关于 spark 2.0 的大概介绍可以直接看上一篇文章，本篇文章是因为最近项目准备从 1.6.1 升级到 2.0，需要对 2.0 有一个整体的了解，所以索性读一遍 2.0 的 release notes，也随手把 release notes 的中文版写下来咯;&lt;/li&gt;
  &lt;li&gt;虽说是中文版，但是一切都是以能理解为主，有的地方不知道怎么翻译，或者我觉得没有必要翻译的，就没有写成中文了，当然欢迎大家提出修改建议了～&lt;/li&gt;
  &lt;li&gt;如果要急着陪女票的话，推荐直接看最后的 &lt;em&gt;7. Spark 2.0, 必须知道的几个点&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上一篇文章： 
&lt;a href=&quot;http://litaotao.github.io/spark-2.0-faster-easier-smarter&quot;&gt;『 Spark 』12. Spark 2.0  | 10 个特性介绍&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;api-stability&quot;&gt;1. API Stability&lt;/h2&gt;

&lt;p&gt;spark 保证 2.x 中非实验性的 api 的稳定性，2.x 中大部分 api 都与 1.x 中保持一致，但是删除了一些 api，更新了一些 api，并且有部分 api 打算在后续升级中移除，具体见下面，完整的列表参考：&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11806&quot;&gt;Spark 2.0 deprecations and removals&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;removals-api&quot;&gt;1.1 Removals API&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Bagel&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;不支持 Hadoop 2.1 及之前老版本&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;The ability to configure closure serializer [闭包序列化？]&lt;/li&gt;
  &lt;li&gt;HTTPBroadcast&lt;/li&gt;
  &lt;li&gt;TTL-based metadata cleaning&lt;/li&gt;
  &lt;li&gt;删除 org.apache.spark.Logging，推荐直接食用 slf4j 包&lt;/li&gt;
  &lt;li&gt;SparkContext.metricsSystem&lt;/li&gt;
  &lt;li&gt;Block-oriented integration with Tachyon (subsumed by file system integration)&lt;/li&gt;
  &lt;li&gt;删掉在 1.x 中标注为 deprecated 的 api&lt;/li&gt;
  &lt;li&gt;Methods on Python DataFrame that returned RDDs (map, flatMap, mapPartitions, etc). They are still available in dataframe.rdd field, e.g. dataframe.rdd.map.&lt;/li&gt;
  &lt;li&gt;Less frequently used streaming connectors, including Twitter, Akka, MQTT, ZeroMQ [不知道为啥要删掉这些 api，估计是因为 structure streaming 改动比较大，难以实现这些 connector 吧]&lt;/li&gt;
  &lt;li&gt;Hash-based shuffle manager&lt;/li&gt;
  &lt;li&gt;History serving functionality from standalone Master&lt;/li&gt;
  &lt;li&gt;For Java and Scala, DataFrame no longer exists as a class. As a result, data sources would need to be updated.&lt;/li&gt;
  &lt;li&gt;Spark EC2 script 被迁移到另外一个 repo，本身与 spark 框架无关&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;behavior-changes-api&quot;&gt;1.2 Behavior Changes API&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;默认使用 scala 2.11 编译，之前默认是 2.10&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;sparksql 中，float 数据类型被解析成 decimal 类型，之前是被解析成 double 类型&lt;/li&gt;
  &lt;li&gt;Kryo 升级到 3.0&lt;/li&gt;
  &lt;li&gt;java 中，RDD.flatMap 和 RDD.mapPartitions 中的函数不需要返回所有数据，只需要能返回一个迭代器即可&lt;/li&gt;
  &lt;li&gt;Java RDD’s countByKey and countAprroxDistinctByKey now returns a map from K to java.lang.Long, rather than to java.lang.Object.&lt;/li&gt;
  &lt;li&gt;When writing Parquet files, the summary files are not written by default. To re-enable it, users must set “parquet.enable.summary-metadata” to true.&lt;/li&gt;
  &lt;li&gt;The DataFrame-based API (spark.ml) now depends upon local linear algebra in spark.ml.linalg, rather than in spark.mllib.linalg.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deprecations&quot;&gt;1.3 Deprecations&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Mesos 中的 Fine-grained 模式&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;不支持 Java 7&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;不支持 Support for Python 2.6&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;core-and-spark-sql&quot;&gt;2. Core and Spark SQL&lt;/h2&gt;

&lt;h3 id=&quot;programming-apis&quot;&gt;2.1 Programming APIs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;统一 DataFrame 和 Dataset，在 Scala 和 Java 中, DataFrame 和 Dataset 完成合并；在 Python 和 R 中, DataFrame 和 Dataset 没有合并；&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;SparkSession: 新的spark 程序入口，SQLContext 和 HiveContext 仍然可用；&lt;/li&gt;
  &lt;li&gt;新的 streaming 配置；&lt;/li&gt;
  &lt;li&gt;新的 accumulator API；&lt;/li&gt;
  &lt;li&gt;A new, improved Aggregator API for typed aggregation in Datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sql&quot;&gt;2.2 SQL&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Spark 2.0 完全支持 SQL2003 标准.&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更原生带 sql 解析器；&lt;/li&gt;
  &lt;li&gt;Native DDL command implementations&lt;/li&gt;
  &lt;li&gt;支持子查询，包括：
    &lt;ul&gt;
      &lt;li&gt;Uncorrelated Scalar Subqueries&lt;/li&gt;
      &lt;li&gt;Correlated Scalar Subqueries&lt;/li&gt;
      &lt;li&gt;NOT IN predicate Subqueries (in WHERE/HAVING clauses)&lt;/li&gt;
      &lt;li&gt;IN predicate subqueries (in WHERE/HAVING clauses)&lt;/li&gt;
      &lt;li&gt;(NOT) EXISTS predicate subqueries (in WHERE/HAVING clauses)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;View canonicalization support&lt;/li&gt;
  &lt;li&gt;In addition, when building without Hive support, Spark SQL should have almost all the functionality as when building with Hive support, with the exception of Hive connectivity, Hive UDFs, and script transforms.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;new-features&quot;&gt;2.3 New Features&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;原生支持 CSV 数据源, 基于 Databricks 的 spark-csv 包；&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;cache 和运行时的堆外内存管理&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Hive style bucketing support&lt;/li&gt;
  &lt;li&gt;Approximate summary statistics using sketches, including approximate quantile, Bloom filter, and count-min sketch.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;performance-and-runtime&quot;&gt;2.4 Performance and Runtime&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;2～10 倍的性能提升，得益于 whole stage code generation 方案；&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;改善 Parquet 文件的扫描性能&lt;/li&gt;
  &lt;li&gt;改善 ORC performance&lt;/li&gt;
  &lt;li&gt;改善 Catalyst query 优化器&lt;/li&gt;
  &lt;li&gt;改善 window function&lt;/li&gt;
  &lt;li&gt;Automatic file coalescing for native data sources&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mllib&quot;&gt;3. MLlib&lt;/h2&gt;

&lt;p&gt;在 2.x 中，DataFrame-based API 会是主要开发，维护的新的 mllib api。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ML persistence: The DataFrames-based API provides near-complete support for saving and loading ML models and Pipelines in Scala, Java, Python, and R. See &lt;a href=&quot;https://databricks.com/blog/2016/05/31/apache-spark-2-0-preview-machine-learning-model-persistence.html&quot;&gt;this blog&lt;/a&gt; post and the following JIRAs for details: SPARK-6725, SPARK-11939, SPARK-14311.&lt;/li&gt;
  &lt;li&gt;MLlib in R: SparkR now offers MLlib APIs for generalized linear models, naive Bayes, k-means clustering, and survival regression.&lt;/li&gt;
  &lt;li&gt;Python: PySpark now offers many more MLlib algorithms, including LDA, Gaussian Mixture Model, Generalized Linear Regression, and more.&lt;/li&gt;
  &lt;li&gt;Algorithms added to DataFrames-based API: Bisecting K-Means clustering, Gaussian Mixture Model, MaxAbsScaler feature transformer.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sparkr&quot;&gt;4. SparkR&lt;/h2&gt;

&lt;p&gt;最大的改善是 2.x 中，sparkr 支持3个 udf: dapply, gapply, and lapply.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Improved algorithm coverage for machine learning in R, including naive Bayes, k-means clustering, and survival regression.&lt;/li&gt;
  &lt;li&gt;Generalized linear models support more families and link functions.&lt;/li&gt;
  &lt;li&gt;Save and load for all ML models.&lt;/li&gt;
  &lt;li&gt;More DataFrame functionality: Window functions API, reader, writer support for JDBC, CSV, SparkSession&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;5. Streaming&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;新的 streaming 框架 Structured Streaming, 其中 DStream API 大多数都是处于试验阶段，并且只支持 Kafka 0.10 的connector.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;dependency-packaging-and-operations&quot;&gt;6. Dependency, Packaging, and Operations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Spark 2.0 no longer requires a fat assembly jar for production deployment.&lt;/li&gt;
  &lt;li&gt;Akka dependency has been removed, and as a result, user applications can program against any versions of Akka.&lt;/li&gt;
  &lt;li&gt;Support launching multiple Mesos executors in coarse grained Mesos mode.&lt;/li&gt;
  &lt;li&gt;Kryo version is bumped to 3.0.&lt;/li&gt;
  &lt;li&gt;The default build is now using Scala 2.11 rather than Scala 2.10.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark-20-&quot;&gt;7. Spark 2.0, 必须知道的几个点&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;不支持 Hadoop 2.1 及之前老版本&lt;/li&gt;
  &lt;li&gt;默认使用 scala 2.11 编译，之前默认是 2.10&lt;/li&gt;
  &lt;li&gt;Mesos 中的 Fine-grained 模式 [Deprecations]&lt;/li&gt;
  &lt;li&gt;不支持 Java 7 [Deprecations]&lt;/li&gt;
  &lt;li&gt;不支持 Support for Python 2.6 [Deprecations]&lt;/li&gt;
  &lt;li&gt;Spark 2.0 完全支持 SQL2003 标准&lt;/li&gt;
  &lt;li&gt;原生支持 CSV 数据源, 基于 Databricks 的 spark-csv 包；&lt;/li&gt;
  &lt;li&gt;SparkSession: 新的spark 程序入口，SQLContext 和 HiveContext 仍然可用；&lt;/li&gt;
  &lt;li&gt;sql中 2～10 倍的性能提升，得益于 whole stage code generation 方案；&lt;/li&gt;
  &lt;li&gt;统一 DataFrame 和 Dataset，在 Scala 和 Java 中, DataFrame 和 Dataset 完成合并；在 Python 和 R 中, DataFrame 和 Dataset 没有合并；&lt;/li&gt;
  &lt;li&gt;cache 和运行时的堆外内存管理&lt;/li&gt;
  &lt;li&gt;新的 streaming 框架 Structured Streaming, 其中 DStream API 大多数都是处于试验阶段，并且只支持 Kafka 0.10 的connector.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-1&quot;&gt;14. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/releases/spark-release-2-0-0.html&quot;&gt;Spark Release 2.0.0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-11806&quot;&gt;Spark 2.0 deprecations and removals&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://spark-summit.org/2016/events/apache-spark-mllib-20-preview-data-science-and-production/&quot;&gt;APACHE SPARK MLLIB 2.0 PREVIEW: DATA SCIENCE AND PRODUCTION&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark?s=inner&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts?s=inner&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model?s=inner&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd?s=inner&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper?s=inner&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model?s=inner&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction?s=inner&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing?s=inner&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark?s=inner&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance?s=inner&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-mlib-machine-learning?s=inner&quot;&gt;『 Spark 』11. spark 机器学习&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-2.0-faster-easier-smarter?s=inner&quot;&gt;『 Spark 』12. Spark 2.0 特性介绍&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner&quot;&gt;『 Spark 』13. Spark 2.0 Release Notes 中文版 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-sql-parquet-optimize?s=inner&quot;&gt;『 Spark 』14. 一次 Spark SQL 性能优化之旅&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 读书笔记 』坚持读书 6 个多月的感受</title>
     <link href="/books-recommend-and-summarize-on-july-2016"/>
     <updated>2016-08-05T00:00:00+08:00</updated>
     <id>/books-recommend-and-summarize-on-july-2016</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;计划是每月读 5-10 本书，书籍类型大概是三个方面的：金融，技术，创业。之所以选择这三个方面，一方面是因为自己对这三个方面都很有兴趣，其次是被 linkedin 创始人 Hoffman 的 &lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;ABZ 理论&lt;/a&gt; 深度影响。建议大家都看看 abz 理论那篇文章，如果我有空，也会整理一些常用的这类理论模型到博客里的。&lt;/p&gt;

&lt;p&gt;月底读书总结的形式都很简单，只是简单的一个列表和简单的书评，对觉得比较好的书会有单独的读书笔记。另外推荐大家用 excel 来做一些简单的工作管理，我现在就用 google docs 来做工作安排和读书计划，个人感觉比一些常用的神马协同软件强大太多了，简单，够用，就行了。工作中见过太多人把时间都花到使用那些协同软件上去，不得不说避重就轻了，适得其反，哈哈。&lt;/p&gt;

&lt;p&gt;下面是一张我用 google docs 来做本月读书安排的截图，不同颜色代表不同类别的数据，清晰明了实用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/book-reading-05.png&quot; alt=&quot;book-reading-05.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;七八月不准备看新书了，着重想把最近半年看的书做一个小结，其一是 review 一下看过的好书，巩固一下知识，其二也算是温故知新嘛。&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;ps: 我对好书的定义很简单：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给自己有所启发的&lt;/li&gt;
  &lt;li&gt;高质量的，专业的教程类书籍&lt;/li&gt;
  &lt;li&gt;后期会再度回首的书&lt;/li&gt;
  &lt;li&gt;看完后会打算赠送给盆友看的书&lt;/li&gt;
  &lt;li&gt;留着给儿子看的书 [好吧，目前我只有个宝贝侄儿，哈哈]&lt;/li&gt;
  &lt;li&gt;最后一条，印刷质量要好&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上月读书总结：&lt;a href=&quot;../books-recommend-and-summarize-on-may-2016&quot;&gt;『 读书笔记 』6月读书总结｜博文推荐&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 最近几个月的感受&lt;/h2&gt;

&lt;p&gt;自从年后开始安排每月读书计划来，每个月都会读一些书籍，分技术，创业，金融几大方面的。一开始不知道是不是能坚持下来，当时的打算是 &lt;em&gt;不管长期下来能否坚持下来，总该试试吧&lt;/em&gt;。后来没想到一开始就顺利的完成计划，真的没想到自己能在一个月内看完十来本书，而且都不是滥竽充数的去看，而且后来慢慢的能接受这种节奏了。&lt;/p&gt;

&lt;p&gt;最近两月不打算看新书，准备把过去半年来看的书，博文回顾一下，温故知新嘛。&lt;/p&gt;

&lt;p&gt;很多朋友问我怎么做到一个月看十来本书的，也问我看完折么多书有什么感受。我有时候同样也在心里问自己这些问题，发现感受颇深，下面分条简单说说自己的感受，希望和大家共勉：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;凡事只要你想做，都应该去尝试尝试&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;即使别人说不行，但是如果你真的喜欢，真的想做，也该去尝试尝试。就像《球王贝利》里的贝利一样，推荐大家都可以看看这部纪录片。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;事情的结果很重要，但过程更重要&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;之前觉得看完一本书就算是完成了一个任务一样。直到有一天我开始问自己，怎么判断自己看完一本书是真的“看完” 了。这真的是一个很有趣的问题。同样的问题可以拓展的很多方面，老板交代的任务怎么样才算做完了？客户反馈的需求怎么样才算是解决了？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;爱我所做，做我所爱&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;大学的时候，经常听同学说不喜欢专业，不喜欢课程什么的；工作后，经常听朋友说对现在的工作内容安排不满什么的。其实我以前有经常有这样的想法，特别是刚毕业的时候，大多数毕业生都是抱着指点江山的心态踏出校园，但基本上刚踏入职场都是先做基础的东西，很多人一开始难以接受这个落差，特别是名牌毕业和海外回来的。我自己最近两年的经验，和最近半年的读书感受，觉得有八个字能解决这类似困惑的：爱我所做，做我所爱 －－－ 在你没有能力负担得起自己的爱好和偏执，在你没有能力选择自己所期望的角色的时候，就好好的爱你现在正在做的事情吧；把你正在做的事情做到极致，在这个过程中不断提高，升华自己，总会有你能自由选择角色的一天。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;step by step, one goes far&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;这算是对抱着指点江山的年轻人们的一点建议吧，也是自己一直以来的宗旨。很多时候，想要做完一件事情很容易，但想要做好一件事情往往很难。一个产品，从开发，到测试，到预生产，到最后的生产化，每一步都需要人们的齐心协力才能做完做好。不要去做一触而就，一夜暴富的梦，多花精力，一步一步的提升自己各方面的能力和积累经验，一切都会水到渠成。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 最近半年看过的好书&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;技术
    &lt;ul&gt;
      &lt;li&gt;effective python&lt;/li&gt;
      &lt;li&gt;大型网站技术架构&lt;/li&gt;
      &lt;li&gt;learning spark&lt;/li&gt;
      &lt;li&gt;MongoDB权威指南(第2版)&lt;/li&gt;
      &lt;li&gt;Hadoop.The.Definitive.Guide.4th.Edition&lt;/li&gt;
      &lt;li&gt;Linux工具快速教程&lt;/li&gt;
      &lt;li&gt;cloudera spark guide&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;金融
    &lt;ul&gt;
      &lt;li&gt;金融产品大全&lt;/li&gt;
      &lt;li&gt;估值的艺术&lt;/li&gt;
      &lt;li&gt;公司财务原理，第一章 ～ 第六章&lt;/li&gt;
      &lt;li&gt;主动投资组合管理:创造高收益并控制风险的量化投资方法(原书第2版) - 第一部分&lt;/li&gt;
      &lt;li&gt;研报系列：行业轮动&lt;/li&gt;
      &lt;li&gt;quantcon 2016&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;创业
    &lt;ul&gt;
      &lt;li&gt;逻辑思维 1&lt;/li&gt;
      &lt;li&gt;从0到1&lt;/li&gt;
      &lt;li&gt;创业维艰：如何完成比难更难的事&lt;/li&gt;
      &lt;li&gt;couresa : Successful Negotiation: Essential Strategies and Skills&lt;/li&gt;
      &lt;li&gt;增长黑客&lt;/li&gt;
      &lt;li&gt;孙子兵法&lt;/li&gt;
      &lt;li&gt;material design&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;生活
    &lt;ul&gt;
      &lt;li&gt;急救手册(修订第9版)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 最近半年看过的好文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;技术
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA5NzkxMzg1Nw==&amp;amp;mid=2653160283&amp;amp;idx=1&amp;amp;sn=23f0391b3a2dc89ac5415ba2b5ace8c5&amp;amp;scene=2&amp;amp;srcid=0802hQQW4XPrsMomZHusM2ZE&amp;amp;key=8dcebf9e179c9f3a89e8f40f109f25e3e404e7e090788e88d863e1cb87c21a4f37908bd69e6b479be5b7754479c091f5&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.11.5+build(15F34)&amp;amp;version=11020201&amp;amp;pass_ticket=EWbmu2ulGZY2GWWK849sZRkPEGEZ7OqlAZ6k9eKwxVTonzo6ZiJNQ74u4t6XvXvu&quot;&gt;作为大数据工程师，你必须熟练运用的性能优化技术&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/100349/&quot;&gt;如果有人问你数据库的原理，叫他看这篇文章&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;blockquote&gt;

        &lt;p&gt;这篇文章是真的不错。&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://geek.csdn.net/news/detail/70162&quot;&gt;向Spark开炮：1.6版本问题总结与趟坑&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.jianshu.com/p/e544b7a76dac&quot;&gt;你应该知道的HTTP基础知识&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://tool.oschina.net/commons?type=5&quot;&gt;HTTP CODE 常用对照表&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&amp;amp;mid=2651640686&amp;amp;idx=1&amp;amp;sn=c2053e953b94f2b6133230c2d0b48d83&amp;amp;scene=0&amp;amp;key=b28b03434249256b1d6facc8de2ef11e0e4dcbdf601d1b76f0eb49a592cba264c4613048cc1946d7e2048b13dd15aa02&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;大数据背后的神秘公式（上）：贝叶斯公式&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&amp;amp;mid=2651640692&amp;amp;idx=1&amp;amp;sn=effef2d07f3afc0e6506d45633e3f771&amp;amp;scene=0&amp;amp;key=b28b03434249256b8a2e9811f53c2873930c9c4ab8fc855d766a6bdac7001085057ba88e71803c6bd7f0a00614c44fc8&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;大数据背后的神秘公式（下）：贝叶斯革命&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=402796490&amp;amp;idx=1&amp;amp;sn=5f9fd2dbd9d0030c954084f2df75d410&amp;amp;scene=0&amp;amp;key=b28b03434249256bcc21f98e1dce38db43a18cba063d4f11b77c9091c999e698be4dfddc847ac0ec70d1785d3f3d0473&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;从算法到案例：推荐系统必读的10篇精选技术文章&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/qwe6112071/article/details/51118761&quot;&gt;git分支原理命令图文解析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://0x0fff.com/spark-architecture/&quot;&gt;Spark Architecture&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/100702/&quot;&gt;面试官如何面试程序员&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/100702/&quot;&gt;纯干货！面试官如何面试程序员&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/99830/&quot;&gt;纯干货！程序员面试的技巧&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;金融
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzAwNTA4NTA0OQ==&amp;amp;mid=2653689783&amp;amp;idx=1&amp;amp;sn=5b41b552f725a120807bbd5ca286eed7&amp;amp;scene=0&amp;amp;key=8dcebf9e179c9f3a25882d9773d95ef90ca36a6be79535b8f3597000d24352afae293f4114788bb8a0dc8b2ee51e6183&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.11.5+build(15F34)&amp;amp;version=11020201&amp;amp;pass_ticket=EWbmu2ulGZY2GWWK849sZRkPEGEZ7OqlAZ6k9eKwxVTonzo6ZiJNQ74u4t6XvXvu&quot;&gt;【方正金工Q培训会议纪要】你不知道的CTA投资学——吴启铭&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzAxODQwODg3Mg==&amp;amp;mid=2651443855&amp;amp;idx=2&amp;amp;sn=6e6ed8aff72260ab11e553a1c3cbf0a1&amp;amp;scene=0&amp;amp;key=8dcebf9e179c9f3a7b3855f10551161877a604d52c81d63df9a09548535700da4730653fc53c422fb9cb15d442928746&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.11.5+build(15F34)&amp;amp;version=11020201&amp;amp;pass_ticket=EWbmu2ulGZY2GWWK849sZRkPEGEZ7OqlAZ6k9eKwxVTonzo6ZiJNQ74u4t6XvXvu&quot;&gt;量化策略的市场容量&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;../images/quant_market.png&quot; alt=&quot;quant_market.png&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA5MDE5OTkyMQ==&amp;amp;mid=2649377759&amp;amp;idx=3&amp;amp;sn=df1e7d2c356b1e3806983166a96e935e&amp;amp;scene=0&amp;amp;key=8dcebf9e179c9f3ac86539ca65b1672ab403097a4cb2d6f8190c24958aeca24b5a1a4c7450c3b059506a7aa8c97576f6&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.11.5+build(15F34)&amp;amp;version=11020201&amp;amp;pass_ticket=EWbmu2ulGZY2GWWK849sZRkPEGEZ7OqlAZ6k9eKwxVTonzo6ZiJNQ74u4t6XvXvu&quot;&gt;聊聊赌场和金融圈最著名的一个数学公式&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.joinquant.com/post/1311?f=study&amp;amp;m=math&quot;&gt;凯利公式，你用对了吗&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;blockquote&gt;

        &lt;p&gt;两篇讲凯利公式的文章，比较不错。&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzAxODQwODg3Mg==&amp;amp;mid=2651442463&amp;amp;idx=5&amp;amp;sn=955d59554989ff0f4ea00b8f5281beab&amp;amp;scene=1&amp;amp;srcid=0523LdGhpiCiPyoRgX1saCSg&amp;amp;key=8d8120cb97983fad4f21efed0a495d8c66cd71210271ea6703679184411ede7245147d179559f367e4f1ff02d7426352&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1713)&amp;amp;version=11020201&amp;amp;pass_ticket=58KQfrxdep1KCNhDrD4Sowiu6JC%2BtWbJVU3lEFWSuJeI2eHPntuvLd0Cgd%2BlcSfM&quot;&gt;160篇精选干货内容精编20160523 私募工场&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;里面的文章都是经典好文啊。&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;创业
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjAzNzMzNTkyMQ==&amp;amp;mid=2653749258&amp;amp;idx=1&amp;amp;sn=82d5929393932fbf1cb97d9acbdd41b5&amp;amp;scene=1&amp;amp;srcid=05188fOCSKGwfCzJfI73ssBE&amp;amp;key=8d8120cb97983fad7f2968069d314547f9679b9bbb4497c084f9246b67b6f6f81d90b0cdb2e55a81153d93e2d75b7a89&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1713)&amp;amp;version=11020201&amp;amp;pass_ticket=CSAsHNzivWgVTZBKGOYlRae9cr0HEYP6s8AVn13yrEYAGDoNhBI7SNSv3teBBk4L&quot;&gt;如何在72小时之内快速搞懂一个陌生行业？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjAzNzMzNTkyMQ==&amp;amp;mid=2653749289&amp;amp;idx=4&amp;amp;sn=a3e57e4400cde387f330e7ea8429d30a&amp;amp;scene=1&amp;amp;srcid=0518elOD5oMp6TNMP4Z9nPxD&amp;amp;key=8d8120cb97983fade74366a3f02b2ceb18dd53e99524441327fe1192e109cf6d1d532b144cd29ce82f208e9e65a7bcc0&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1713)&amp;amp;version=11020201&amp;amp;pass_ticket=CSAsHNzivWgVTZBKGOYlRae9cr0HEYP6s8AVn13yrEYAGDoNhBI7SNSv3teBBk4L&quot;&gt;数据化解析Term Sheet十大核心条款，关于融资的干货都在这儿了&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://colachan.com/post/3502&quot;&gt;优秀配色方案的探索过程&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4ODM1MTMzMQ==&amp;amp;mid=2651791131&amp;amp;idx=2&amp;amp;sn=7512d96b25ba78f4fcb0786f9a2838d4&amp;amp;scene=1&quot;&gt;如何快速在一个陌生领域达到优秀水平&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://36kr.com/p/5046704.html&quot;&gt;“早知道这些我的公司就不会死”系列（一）：CAC、LTV、PBP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://36kr.com/p/5046873.html&quot;&gt;“早知道这些我的公司就不会死”系列（二）：Cohort Analysis&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MTQzNzU2NA==&amp;amp;mid=403145071&amp;amp;idx=1&amp;amp;sn=7ab3a8fd92b622d3cd7362db5b20b82a&amp;amp;scene=0&amp;amp;key=b28b03434249256bf46f5ae8286a91d594b55d0f3f709de24e82865fa245df906c24fdbd0dc7bb12df7f9e8ed45c7a37&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;优秀的数据产品经理如何炼成&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;blockquote&gt;

        &lt;p&gt;这些都是讲方法论的，个人觉得想要在自己所在的行业做到优秀，最核心，最关键的因素是自己打心底爱这个职业。人生两大境界：爱我所做，做我所爱。&lt;/p&gt;
      &lt;/blockquote&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;生活
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzA4NjAzNDg4NA==&amp;amp;mid=2656366443&amp;amp;idx=3&amp;amp;sn=19091f8ca1bd18a1cba55fc88402a7fd&amp;amp;scene=1&amp;amp;srcid=0515hXptbhIi1JhXUGtyqI5r&amp;amp;key=8d8120cb97983fad3adcf075795d583f5889e72bfd0a1874e4d968c4478a422244e16d191be3b8c1c5010484537b5e4f&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1713)&amp;amp;version=11020201&amp;amp;pass_ticket=CSAsHNzivWgVTZBKGOYlRae9cr0HEYP6s8AVn13yrEYAGDoNhBI7SNSv3teBBk4L&quot;&gt;知乎上的48条神回复，针针见血，看完整个人都通透多了&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;哈哈，轻松一下&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5MDMyMzg2MA==&amp;amp;mid=407893431&amp;amp;idx=1&amp;amp;sn=bceacc10da607cb6b0e7c5d14c963b90&amp;amp;scene=0&amp;amp;key=b28b03434249256b37259de5b86de1aed3f2f01e22bb962ca1590d9c6f9966bfcbf006f7be14d7d93377444fe2388ecf&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;情商高就是心里装着别人&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MjM5NzEwNTMwMA==&amp;amp;mid=403311481&amp;amp;idx=1&amp;amp;sn=7b597caceb57c69b3c53c052e0050cf2&amp;amp;scene=0&amp;amp;key=b28b03434249256be55dc6bc20a8bc9b34fe45739f7a6d6ec9fc84dde0eafabb7fa00e636f05592c74d23c3bac40654c&amp;amp;ascene=0&amp;amp;uin=MTAzNTc2NzM4Mg%3D%3D&amp;amp;devicetype=iMac+MacBookAir6%2C2+OSX+OSX+10.10.5+build(14F1605)&amp;amp;version=11020201&amp;amp;pass_ticket=mBoeKJT4SCEkrgKop52x3Dw7dtf706Nn06oeT3552IIocF4nfR7p%2FEc0dm3Jc7Z3&quot;&gt;「滚床单」有哪些优雅的叫法？&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;In Startups And Life, You Need Plan A, B, And Z&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;4. 其他好东西&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=3ZWDA89ckk8&quot;&gt;IBM Analytics for Apache® Spark™ Overview&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;

  &lt;p&gt;IBM Analytics 平台的介绍，video 做得非常好，质量非常高，可以借鉴来做公司介绍，产品介绍，项目介绍等。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.websequencediagrams.com/&quot;&gt;https://www.websequencediagrams.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;

  &lt;p&gt;不错的在线流程图应用。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.import.io/&quot;&gt;import.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-5&quot;&gt;6. 读书总结系列&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-mar-2016&quot;&gt;『 读书笔记 』3月读书总结和推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-apr-2016&quot;&gt;『 读书笔记 』4月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-May-2016&quot;&gt;『 读书笔记 』5月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-June-2016&quot;&gt;『 读书笔记 』6月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-july-2016&quot;&gt;『 读书笔记 』坚持读书 6 个多月的感受&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-sep-2016&quot;&gt;『 读书笔记 』9月，10月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 读书笔记 』6月读书总结｜博文推荐</title>
     <link href="/books-recommend-and-summarize-on-June-and-july-2016"/>
     <updated>2016-07-17T00:00:00+08:00</updated>
     <id>/books-recommend-and-summarize-on-June-and-july-2016</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;计划是每月读 5-10 本书，书籍类型大概是三个方面的：金融，技术，创业。之所以选择这三个方面，一方面是因为自己对这三个方面都很有兴趣，其次是被 linkedin 创始人 Hoffman 的 &lt;a href=&quot;http://techcrunch.com/2012/02/14/in-startups-and-life-you-need-plan-a-b-and-z/&quot;&gt;ABZ 理论&lt;/a&gt; 深度影响。建议大家都看看 abz 理论那篇文章，如果我有空，也会整理一些常用的这类理论模型到博客里的。&lt;/p&gt;

&lt;p&gt;月底读书总结的形式都很简单，只是简单的一个列表和简单的书评，对觉得比较好的书会有单独的读书笔记。另外推荐大家用 excel 来做一些简单的工作管理，我现在就用 google docs 来做工作安排和读书计划，个人感觉比一些常用的神马协同软件强大太多了，简单，够用，就行了。工作中见过太多人把时间都花到使用那些协同软件上去，不得不说避重就轻了，适得其反，哈哈。&lt;/p&gt;

&lt;p&gt;下面是一张我用 google docs 来做本月读书安排的截图，不同颜色代表不同类别的数据，清晰明了实用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/book-reading-06.png&quot; alt=&quot;book-reading-06.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ps: 我对好书的定义很简单：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;给自己有所启发的&lt;/li&gt;
  &lt;li&gt;高质量的，专业的教程类书籍&lt;/li&gt;
  &lt;li&gt;后期会再度回首的书&lt;/li&gt;
  &lt;li&gt;看完后会打算赠送给盆友看的书&lt;/li&gt;
  &lt;li&gt;留着给儿子看的书 [好吧，目前我只有个宝贝侄儿，哈哈]&lt;/li&gt;
  &lt;li&gt;最后一条，印刷质量要好&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上月读书总结：&lt;a href=&quot;../books-recommend-and-summarize-on-June-and-july-2016&quot;&gt;『 读书笔记 』5月读书总结｜博文推荐&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 读书总结&lt;/h2&gt;

&lt;h3 id=&quot;httpswwwamazoncne5ad99e5ad90e585b5e6b395e7b2bee8afbb-e99988e5ae87dpb00127eu7erefsr12ieutf8qid1465825540sr8-2keywordse5ad99e5ad90e585b5e6b395e7b2bee8afbb&quot;&gt;1.1 &lt;a href=&quot;https://www.amazon.cn/%E5%AD%99%E5%AD%90%E5%85%B5%E6%B3%95%E7%B2%BE%E8%AF%BB-%E9%99%88%E5%AE%87/dp/B00127EU7E/ref=sr_1_2?ie=UTF8&amp;amp;qid=1465825540&amp;amp;sr=8-2&amp;amp;keywords=%E5%AD%99%E5%AD%90%E5%85%B5%E6%B3%95+%E7%B2%BE%E8%AF%BB&quot;&gt;孙子兵法&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;这本书买了不知道有多少年了，但是一直没看过。自从今年3月份培养读书习惯来，就把这本书列上了书单，很是期待这本书，作为6月的第一本书来读。内容方面自然不必多说，满满的都是干货，但是这本书传承了千年，我自始自终都抱着敬畏的态度来读，不能随意的评论。但是，我想说，这本书里的内容，不论在从商，创业，处事，个人规划方面都很有借鉴意义。博大精深，值得反复品读。&lt;/p&gt;

&lt;p&gt;总结：抱着敬畏的形态来读这本书，之后还会不间断的回顾，希望能多吸取一些精华和感悟。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne5ad99e5ad90e585b5e6b395e7b2bee8afbb-e99988e5ae87dpb00127eu7erefsr12ieutf8qid1465825540sr8-2keywordse5ad99e5ad90e585b5e6b395e7b2bee8afbb-1&quot;&gt;1.2 &lt;a href=&quot;https://www.amazon.cn/%E5%AD%99%E5%AD%90%E5%85%B5%E6%B3%95%E7%B2%BE%E8%AF%BB-%E9%99%88%E5%AE%87/dp/B00127EU7E/ref=sr_1_2?ie=UTF8&amp;amp;qid=1465825540&amp;amp;sr=8-2&amp;amp;keywords=%E5%AD%99%E5%AD%90%E5%85%B5%E6%B3%95+%E7%B2%BE%E8%AF%BB&quot;&gt;研报：行业轮动系列&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;material-design-httpwikijikexueyuancomprojectmaterial-design&quot;&gt;1.3 &lt;a href=&quot;http://wiki.jikexueyuan.com/project/material-design/&quot;&gt;Material Design 中文版&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;最近两个月对 Material Design 很感兴趣，为了系统的了解 Material Design 的由来，原则和内在的哲理，我安排了这个月读一读 Material Design 的官方资料，因为自己没有这方面的背景，所以是先看极客学院翻译的中文文档，有问题和不理解的地方再阅读 google 的官方文档。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://wiki.jikexueyuan.com/project/material-design/&quot;&gt;Material Design 中文版&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://material.google.com&quot;&gt;Material Design&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;随着 Material Design 最近的流行，一些产品开始采用 Material Design，但是最近又看到有公司抛弃 Material Design。作为一个工程师，我无法评定 Material Design 的好与坏，但是我能说的是，作为一个 PM 或者 Designer，就算不用 Material Design，也是很有必要去了解，甚至是深入研究 Material Design 的。&lt;/p&gt;

&lt;p&gt;总结：作为一个工程师，我还是很喜欢 Material Design 的风格和哲理的。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne9878de696b0e5ae9ae4b989e7aea1e79086-e59088e5bc84e588b6e694b9e58f98e4b896e7958c-e5b883e8b596e681a9c2b7e7bd97e4bcafe9808adpb015mqyzgqrefsr11ieutf8qid1467107628sr8-1keywordse9878de696b0e5ae9ae4b989e7aea1e79086&quot;&gt;1.4 &lt;a href=&quot;https://www.amazon.cn/%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E7%AE%A1%E7%90%86-%E5%90%88%E5%BC%84%E5%88%B6%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C-%E5%B8%83%E8%B5%96%E6%81%A9%C2%B7%E7%BD%97%E4%BC%AF%E9%80%8A/dp/B015MQYZGQ/ref=sr_1_1?ie=UTF8&amp;amp;qid=1467107628&amp;amp;sr=8-1&amp;amp;keywords=%E9%87%8D%E6%96%B0%E5%AE%9A%E4%B9%89%E7%AE%A1%E7%90%86&quot;&gt;重新定义管理: 合弄制改变世界&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;我参加过公司组织的合弄制培训，结合起当时的培训，这本书的内容，已经一些网上总结的 ppt，真心不觉得合弄制这个东西有什么革命性的优势，本质上还是没有什么改变。未来的一两个月我也参与到公司的一个合弄制试水的项目里了，体验体验所谓的合弄制有哪些优劣。&lt;/p&gt;

&lt;p&gt;就合弄制本身而言，其实也没什么坏处，但是在玩看来合弄制是对传统的企业管理矫枉过正了。我们其实只需要参考其中的一些概念和方法，在扁平化管理的基础上搞出一些微创新，制定一些公司内部微创新的规则和奖励机制就完全足够了。而且，我强烈建议公司内部在搞微创新的时候，千万不要往合弄制的身上生搬硬套一些概念，合弄制的概念真心太多了，心累啊～～～&lt;/p&gt;

&lt;p&gt;总结：虽然我不赞同合弄制的很多做法和思想，但捍卫它为自己争取一丝地位的权利吧。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;httpswwwamazoncne590afe7a4bae5bd95-e68993e980a0e794a8e688b7e5969ce788b1e79a84e4baa7e59381-marty-cagandpb00cwqmxdmrefsr11ieutf8qid1467266470sr8-1keywordse590afe7a4bae5bd95efbc9ae68993e980a0e794a8e688b7e5969ce788b1e79a84e4baa7e59381&quot;&gt;1.5 &lt;a href=&quot;https://www.amazon.cn/%E5%90%AF%E7%A4%BA%E5%BD%95-%E6%89%93%E9%80%A0%E7%94%A8%E6%88%B7%E5%96%9C%E7%88%B1%E7%9A%84%E4%BA%A7%E5%93%81-Marty-Cagan/dp/B00CWQMXDM/ref=sr_1_1?ie=UTF8&amp;amp;qid=1467266470&amp;amp;sr=8-1&amp;amp;keywords=%E5%90%AF%E7%A4%BA%E5%BD%95%EF%BC%9A%E6%89%93%E9%80%A0%E7%94%A8%E6%88%B7%E5%96%9C%E7%88%B1%E7%9A%84%E4%BA%A7%E5%93%81&quot;&gt;启示录：打造用户喜爱的产品&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;很不错的一本书，大多数人会把这本书当作产品方面的书，可我觉得，这本书不仅仅是为产品经理写的，还是为公司管理层，项目负责人写的。书很薄，但内容很优质，很久没有看到这种干货漫漫的书了。里面有很多在现实中会遇见的问题，作者的叙述能力很强，有时候会让读者如临其境。很具有实操性的一本书，建议第一遍快速看完，然后第二遍细细品读，之后可以时不时拿来翻翻，对比现实工作中遇到的一些问题场景。&lt;/p&gt;

&lt;p&gt;最后两章［40: 最佳实践经验；41: 产品经理的反省清单］值得反复品读。&lt;/p&gt;

&lt;p&gt;对了，这本书里也提到了一些不错的其它书籍，感兴趣的也可以看看作者推荐的那些书。&lt;/p&gt;

&lt;p&gt;总结：非常好，实操性强，没有废话，干货很多的一本书。建议产品经理，工程师，项目负责人，公司管理层的人都应该读读。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;cloudera-spark-guidehttpwwwclouderacomdocumentationenterpriselatesttopicssparkhtml&quot;&gt;1.6 &lt;a href=&quot;http://www.cloudera.com/documentation/enterprise/latest/topics/spark.html&quot;&gt;cloudera spark guide&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;非常高质量的 spark guide，可以和官方的一起读读，里面会有一些比较细节的问题，比如在 python 编写的 spark 应用中，如何打包应用的依赖等。遇到了很多我现实生活中遇到的问题，很有帮助。&lt;/p&gt;

&lt;p&gt;总结：建议和官方 guide 一起看看，能看完，看懂 70% 就可以直接开干了。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;1.7 公司财务原理，第五，第六章&lt;/h3&gt;

&lt;p&gt;啥都不说了，看过我之前的读书总结的都知道，我对这本书简直就是四粉，粉得彻彻底底的。&lt;/p&gt;

&lt;p&gt;总结：best of the best.&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;linux&quot;&gt;1.8 Linux工具快速教程&lt;/h3&gt;

&lt;p&gt;给实习生推荐的 linux 基本教程，我自己也再看了一遍，非常好，比一些贴命令参数的纸板书好了几个档次。不过里面有一些很细节的，不太常用的东西，不是太有必要一口吃完。建议初学者看完基础那一栏就 ok 了，以后遇到问题了再来翻翻。&lt;/p&gt;

&lt;p&gt;总结：The power of open-source, more than you can imagine.&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;quantcon-2016&quot;&gt;1.9 quantcon 2016&lt;/h3&gt;

&lt;p&gt;quantcon 2016 上的所有 slide，video 只看了一部分。很有用，很有启发，这个资料是私密的，建议想学习的矿友们去官方网站上咨询咨询。&lt;/p&gt;

&lt;p&gt;总结：风已来，等你一起飞。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* * * * *&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;1.10 2016券商中期策略&lt;/h3&gt;

&lt;p&gt;总结：券商中期策略简直白花齐放，不仅是观点，还有行文组织上，有的甚至给人的感觉就是一两天赶工出来的报告。&lt;/p&gt;

&lt;p&gt;推荐指数：&lt;code class=&quot;highlighter-rouge&quot;&gt;* *&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;2. 优质产品&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.websequencediagrams.com/&quot;&gt;https://www.websequencediagrams.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不错的在线流程图应用。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;user-&amp;gt;WebApi: GET /jars
WebApi-&amp;gt;JarManager: ListJars
JarManager-&amp;gt;WebApi: Map(appName -&amp;gt; uploadTime)
WebApi-&amp;gt;user: 200 + JSON&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;../images/websequencediagrams.png&quot; alt=&quot;websequencediagrams.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;5. 读书总结系列&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-mar-2016&quot;&gt;『 读书笔记 』3月读书总结和推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-apr-2016&quot;&gt;『 读书笔记 』4月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-May-2016&quot;&gt;『 读书笔记 』5月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-June-2016&quot;&gt;『 读书笔记 』6月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-july-2016&quot;&gt;『 读书笔记 』坚持读书 6 个多月的感受&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;../books-recommend-and-summarize-on-sep-2016&quot;&gt;『 读书笔记 』9月，10月读书总结｜博文推荐&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>『 Tips 』SSH 免密码登录</title>
     <link href="/tips-ssh-without-password"/>
     <updated>2016-07-15T00:00:00+08:00</updated>
     <id>/tips-ssh-without-password</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;每次登录远程服务器都要输密码！！！&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/no-way.gif&quot; alt=&quot;no-way&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 事前准备&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;本地机器：local&lt;/li&gt;
  &lt;li&gt;远程机器：remote&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 实操步骤&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;本地机器生成公钥，私钥: &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh-keygen -t rsa&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;taotao@mac007:~&lt;span class=&quot;nv&quot;&gt;$ssh&lt;/span&gt;-keygen -t rsa
Generating public/private rsa key pair.
Enter file &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;which to save the key &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/Users/chenshan/.ssh/id_rsa&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;: /Users/chenshan/.ssh/id_rsa_test
Enter passphrase &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;empty &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;no passphrase&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;:
Enter same passphrase again:
Your identification has been saved &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /Users/chenshan/.ssh/id_rsa_test.
Your public key has been saved &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /Users/chenshan/.ssh/id_rsa_test.pub.
The key fingerprint is:
SHA256:gYV/PFrA08nktGUZ8LlFJ/Fhg7wDRjYQslmwf4UYJZc taotao@mac007
The key&lt;span class=&quot;s1&quot;&gt;&#39;s randomart image is:
+---[RSA 2048]----+
|       =oXOO*o==.|
|      .oXoXE+=.+o|
|      .=.=+.+.o .|
|        o.= .=   |
|        S= o. .  |
|        . .      |
|                 |
|                 |
|                 |
+----[SHA256]-----+

taotao@mac007:~$ls ~/.ssh/ | grep test
id_rsa_test
id_rsa_test.pub&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;上传本地公钥到远程机器: &lt;code class=&quot;highlighter-rouge&quot;&gt;scp ~/.ssh/id_rsa_test.pub username@remote:.ssh/id_rsa_test.pub&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-shell&quot; data-lang=&quot;shell&quot;&gt;&lt;span class=&quot;gp&quot;&gt;taotao@mac007:~$ &lt;/span&gt;scp ~/.ssh/id_rsa_test.pub username@remote:.ssh/id_rsa_test.pub
username@remote&lt;span class=&quot;s1&quot;&gt;&#39;s password:
id_rsa_test.pub                                                                                   100%  412     0.4KB/s   00:00&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;在远程机器上设置 &lt;code class=&quot;highlighter-rouge&quot;&gt;authorized_keys&lt;/code&gt; : &lt;code class=&quot;highlighter-rouge&quot;&gt;cat /root/.ssh/id_rsa_test.pub  &amp;gt;&amp;gt; /root/.ssh/authorized_keys&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-3&quot;&gt;3. 完成&lt;/h2&gt;
</content>
   </entry>
   
   <entry>
     <title>『 Spark 』12. Spark 2.0  | 10 个特性介绍</title>
     <link href="/spark-2.0-faster-easier-smarter"/>
     <updated>2016-06-16T00:00:00+08:00</updated>
     <id>/spark-2.0-faster-easier-smarter</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。&lt;/p&gt;

&lt;p&gt;其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本号还是必要的。 &lt;br /&gt;
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。&lt;/p&gt;

&lt;p&gt;Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦；3. 点击右边目录上方的 &lt;em&gt;present mode&lt;/em&gt; 哦。&lt;/p&gt;

&lt;h2 id=&quot;spark-20-&quot;&gt;1. Spark 2.0 !&lt;/h2&gt;

&lt;p&gt;还记得我们的&lt;a href=&quot;../spark-dataframe-introduction&quot;&gt;第七篇 Spark 博文&lt;/a&gt;里吗？里面我用三点来总结 spark dataframe 的好处：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-2.0-1.png&quot; alt=&quot;spark-2.0-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当时是主要介绍 spark 里的 dataframe，今天是想总结一下 spark 2.0 的一些重大更新，准备过段时间［等到 2.0.1 或者 2.1 出来了就］切换到 spark 2.x 来。当我看官方的一些介绍和一些相关文章的时候，我发现 spark 2.0 的特点，也可以用第七篇里总结的 dataframe 的特点来说明，那就是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;write less : 写更少的代码&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;do more : 做更多的事情&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;faster : 以更快的速度&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;真心觉得 spark 做得很不错，databricks 做得太赞了，现在 databricks 的社区版 [DCE : Databricks Community Edition] 也开放注册了，大家还没有注册的赶紧去体验这个产品吧，so amazing，注册链接：&lt;a href=&quot;community.cloud.databricks.com&quot;&gt;community.cloud.databricks.com&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;言归正传，下面从几个亮点来总结一下 spark 2.0 的更新，基本上都是看官方文档，相关的 video，slide 和一些技术博文来的，参考的文章都会在后文列出来的。&lt;/p&gt;

&lt;h2 id=&quot;spark-&quot;&gt;2. Spark 版本号说明&lt;/h2&gt;

&lt;p&gt;如图是 spark 版本号的三个不同数字的介绍，以 &lt;em&gt;1.6.0&lt;/em&gt; 版本举例：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;1 : major version&lt;/em&gt; : 代表大版本更新，一般都会有一些 api 的变化，以及大的优化或是一些结构的改变；&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;6 : minor version&lt;/em&gt; : 代表小版本更新，一般会新加 api，或者是对当前的 api 就行优化，或者是其他内容的更新，比如说 WEB UI 的更新等等；&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;0 : patch version&lt;/em&gt; : 代表修复当前小版本存在的一些 bug，基本不会有任何 api 的改变和功能更新；记得有一个大神曾经说过，如果要切换 spark 版本的话，最好选 &lt;em&gt;patch version&lt;/em&gt; 非 0 的版本，因为一般类似于 &lt;em&gt;1.2.0, … 1.6.0&lt;/em&gt; 这样的版本是属于大更新的，有可能会有一些隐藏的 bug 或是不稳定性存在，所以最好选择 &lt;em&gt;1.2.1, … 1.6.1&lt;/em&gt; 这样的版本。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-2.0-2.png&quot; alt=&quot;spark-2.0-2.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;3. 特性 1 - 官方文档&lt;/h2&gt;

&lt;p&gt;spark 2.0 似乎对官方文档做了比较大的改变，赞，这里是 2.0 预览版的文档链接，等不及的小伙伴们可以先看了：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/2.0.0-preview/&quot;&gt;2.0.0-preview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/index.html&quot;&gt;master-docs &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://home.apache.org/~pwendell/spark-nightly/spark-branch-2.0-docs/latest/&quot;&gt;2.0.0 docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-&quot;&gt;4. 特性 2 - 支持标准 SQL 语句&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;On the SQL side, we have significantly expanded the SQL capabilities of Spark, with the introduction of a new ANSI SQL parser and support for subqueries. Spark 2.0 can run all the 99 TPC-DS queries, which require many of the SQL:2003 features.&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;上面提到的 &lt;em&gt;TPC-DS&lt;/em&gt; 这个概念没有必要去了解了，我是 google 了之后才知道的，如果感兴趣的话可以看这个链接：&lt;a href=&quot;https://developer.ibm.com/hadoop/2015/11/30/99-tpc-ds-queries-integrated-into-spark-sql-perf/&quot;&gt;TPC-DS&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;总结下来：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Spark 2.0 中, SQL:2003 语法全部支持了，下面是 sql 语法的发展历程，可以说，虽然 sql 2003 之后又更新了两个版本的语法，但在实际使用情况中，sql 2003 已经完全能 handle 99% 的场景了。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;

    &lt;p&gt;1986年，ANSI X3.135-1986，ISO/IEC 9075:1986，SQL-86    &lt;br /&gt;
1989年，ANSI X3.135-1989，ISO/IEC 9075:1989，SQL-89     &lt;br /&gt;
1992年，ANSI X3.135-1992，ISO/IEC 9075:1992，SQL-92（SQL2）    &lt;br /&gt;
1999年，ISO/IEC 9075:1999，SQL:1999（SQL3）   &lt;br /&gt;
2003年，ISO/IEC 9075:2003，SQL:2003  &lt;br /&gt;
2008年，ISO/IEC 9075:2008，SQL:2008  &lt;br /&gt;
2011年，ISO/IEC 9075:2011，SQL:2011&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Spark 2.0 中，更新了新的 SQL 解析器，可以支持子查询了，特地重复一下，因为基本上所有复杂的 sql 语句都会用到子查询，官方有例子: &lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2728434780191932/1483312212640900/6987336228780374/latest.html&quot;&gt;Subqueries in Apache Spark 2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dataframes-and-datasets-api&quot;&gt;5. 特性 3 - 统一 DataFrames and Datasets API&lt;/h2&gt;

&lt;p&gt;在 spark 2.0 中，把 dataframes 当作是一种特殊的 datasets，&lt;strong&gt;&lt;em&gt;dataframes = datasets[row]&lt;/em&gt;&lt;/strong&gt;，把两者统一为 datasets。但是需要注意的是，目前只更新了 scala 和 java 的api，python中尚未更新。而且 spark 2.0 中引入了 structured streaming 的概念，需要 dataframe 的支持，其中的 dataframe 也已经用 datasets[row] 来实现了。&lt;/p&gt;

&lt;p&gt;官方的关于 DataSets API 的使用说明：&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690871/4814681571895601/latest.html&quot;&gt;Dataset API&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;sparksession&quot;&gt;6. 特性 4 - SparkSession&lt;/h2&gt;

&lt;p&gt;在 spark 2.0 之前，sparkContext 是 Spark应用的入口。除了 sparkContext，还有 sqlContext，StreamingContext，HiveContext 等其他入口。然而到了 spark 2.0 后，因为逐渐要采用 DataFrame 和 DataSets 作为 API 使用，需要一个统一的入口点，所以就诞生了 SparkSession。本质上，可以简单的把 SparkSession 理解成 sparkContext, sqlContext, StreamingContext, HiveContext 的统一封装。&lt;/p&gt;

&lt;p&gt;下面是一个来自官方的 demo：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.SparkSession&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;local&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;my-spark-app&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark.some.config.option&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;config-value&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;值得注意的一个点是，在 2.0 之前，启动 spark repl 时，会自动给你创建一个 sparkContext，叫做 &lt;em&gt;sc&lt;/em&gt;，但在 2.0 之后，启动 spark repl 时会自动给你创建一个 SparkSession，叫做 &lt;em&gt;spark&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-2.0-3.png&quot; alt=&quot;spark-2.0-3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里有一个 databricks 出的关于 SparkSession 的说明文档和使用方法：&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690884/4814681571895601/latest.html&quot;&gt;SparkSession - a new entry point&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;accumulator-api&quot;&gt;7. 特性 5 - 新的 Accumulator API&lt;/h2&gt;

&lt;p&gt;spark 2.0 设计了新的 Accumulator API，用户可以基于默认的 Accumulator 实现自己定义的 Accumulator，当然老的 Accumulator 还是保留使用的。&lt;/p&gt;

&lt;p&gt;下面是一个用户自定义 Accumulator 的例子：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-scala&quot; data-lang=&quot;scala&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VectorAccumulatorParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;AccumulatorParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;zero&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;initialValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Vector.zeros&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;initialValue.size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;addInPlace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;v1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;v2&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;#&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Then&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Accumulator&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;vecAccum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accumulator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(...),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VectorAccumulatorParam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;而且 spark 2.0 里可以在 web ui 里查看 Accumulator 的数据了，非常方便［注明一下，这里我没有尝试过在 2.0 之前是否可以在 web ui 里查看 Accumulator 的数据，如果有写错了请大家指出哈，谢谢］&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-2.0-4.png&quot; alt=&quot;spark-2.0-4.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;dataframe-based-machine-learning&quot;&gt;8. 特性 6 - DataFrame Based Machine Learning&lt;/h2&gt;

&lt;p&gt;在上篇文章里 &lt;a href=&quot;../spark-mlib-machine-learning&quot;&gt;『 Spark 』11. spark 机器学习&lt;/a&gt;，我们也提到过，从 2.0 开始，spark machine learning 开始采用基于 dataframe 开发的 ml package，基于 RDD API 的 mllib 将不再开发新 feature，只做维护。&lt;/p&gt;

&lt;h2 id=&quot;machine-learning-pipeline-persistence&quot;&gt;9. 特性 7 - Machine learning pipeline persistence&lt;/h2&gt;

&lt;p&gt;spark 2.0 支持机器学习持久化了，虽然 2.0 之前也有类似的功能，但在这方面，2.0 有两大亮点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;不仅可以 save &amp;amp; load 模型，还可以 save &amp;amp; load 模型的 pipeline；&lt;/li&gt;
  &lt;li&gt;可以跨语言 save &amp;amp; load 模型，比如说你用 scala 实现了一个模型，并且 save 到磁盘上，之后可以用 python 来 load 这个模型；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里有官方出的一个介绍文档和使用说明：&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/100429797847215/4814681571895601/latest.html&quot;&gt;Saving &amp;amp; loading Machine Learning (ML) models&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;distributed-algorithms-in-r&quot;&gt;10. 特性 8 - Distributed algorithms in R&lt;/h2&gt;

&lt;p&gt;也可以用 R 来实现一些机器学习算法了： Generalized Linear Models (GLM), Naive Bayes, Survival Regression, and K-Means.&lt;/p&gt;

&lt;h2 id=&quot;whole-stage-code-generation&quot;&gt;11. 特性 9 - Whole-stage code generation&lt;/h2&gt;

&lt;p&gt;spark 2.0 性能上会有较大的提升，根据官方文档，2.0 会引入新的物理执行引擎 &lt;em&gt;new Tungsten execution engine&lt;/em&gt;，相对于之前的执行引擎［之前也有 code generation］，新的物理执行引擎会充分利用 &lt;em&gt;内存，cpu，cpu 寄存器&lt;/em&gt; 三者，最大化的提升代码执行速度。&lt;/p&gt;

&lt;p&gt;关于 &lt;em&gt;new Tungsten execution engine&lt;/em&gt; 的原理，可以参考这篇官方博客：&lt;a href=&quot;https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html&quot;&gt;Apache Spark as a Compiler: Joining a Billion Rows per Second on a Laptop : Deep dive into the new Tungsten execution engine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里有官方做的一个简单的测试：&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/293651311471490/5382278320999420/latest.html&quot;&gt;Performance of Spark 2.0’s Tungsten engine&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;下图是一个简要的性能对比截图：
&lt;img src=&quot;../images/spark-2.0-5.png&quot; alt=&quot;spark-2.0-5.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;structured-streaming&quot;&gt;12. 特性 10 - Structured Streaming&lt;/h2&gt;

&lt;p&gt;这个就不用说了，是 2.0 的三大更新之一。官方的这句话很有意思: &lt;em&gt;the simplest way to compute answers on streams of data is to not having to reason about the fact that it is a stream.&lt;/em&gt;，中文翻译来说就是说：&lt;em&gt;处理流式计算最简单的方法，就是不要特地去区分流式计算与非流式计算的区别［因为归根结底，他们都是数据，我们要区分的，并不是数据本身，而是我们处理数据的方式］&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;在 rxin 的这个 slide 里，&lt;a href=&quot;http://www.slideshare.net/databricks/apache-spark-20-faster-easier-and-smarter&quot;&gt;Apache Spark 2.0: Faster, Easier, and Smarter&lt;/a&gt;，第 17 ～ 26 也专门有说 2.0 里的 structure streaming，非常值得借鉴。&lt;/p&gt;

&lt;p&gt;下面是其中两张需要理解的 ppt 截图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/spark-2.0-6.png&quot; alt=&quot;spark-2.0-6.png&quot; /&gt;
&lt;img src=&quot;../images/spark-2.0-7.png&quot; alt=&quot;spark-2.0-7.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;next&quot;&gt;13. Next&lt;/h2&gt;

&lt;p&gt;最近 databricks 出了一篇非常不错的文章，讲 spark 的一些概念的，个人觉得非常不错，下一篇就翻译这篇文章吧。届时大家可以结合起第二篇文章一起理解：&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts?s=inner&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;14. 打开微信，扫一扫，点一点，棒棒的，^_^&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/wechat_pay_6-6.png&quot; alt=&quot;wechat_pay_6-6.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ZFBgY0PwUeY&amp;amp;feature=youtu.be&quot;&gt;Spark 2 0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/apache-spark-20-faster-easier-and-smarter&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;slide&lt;/code&gt; Spark 2 0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.slideshare.net/databricks/apache-spark-20-faster-easier-and-smarter&quot;&gt;Apache Spark 2.0: Faster, Easier, and Smarter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2016/05/11/spark-2-0-technical-preview-easier-faster-and-smarter.html&quot;&gt;Preview of Apache Spark 2.0 now on Databricks Community Edition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html&quot;&gt;Technical Preview of Apache Spark 2.0 Now on Databricks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.iteblog.com/archives/1673&quot;&gt;Spark 2.0介绍：SparkSession创建和使用相关API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690884/4814681571895601/latest.html&quot;&gt;SparkSession - a new entry point&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.madhukaraphatak.com/introduction-to-spark-two-part-1/&quot;&gt;http://blog.madhukaraphatak.com/introduction-to-spark-two-part-1/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://vishnuviswanath.com/spark_session.html&quot;&gt;Experiment with Spark 2.0 - Session&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://spark.apache.org/docs/2.0.0-preview/&quot;&gt;Spark Programming Guide of 2.0 Preview&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.iteblog.com/archives/tag/spark/page/2&quot;&gt;Spark Series on Iteblog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/293651311471490/5382278320999420/latest.html&quot;&gt;Performance of Spark 2.0’s Tungsten engine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html&quot;&gt;Apache Spark as a Compiler: Joining a Billion Rows per Second on a Laptop : Deep dive into the new Tungsten execution engine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/2727501386611546/5382278320999420/latest.html&quot;&gt;Demo 2. SparkSession - the new entry point&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690871/4814681571895601/latest.html&quot;&gt;Dataset API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/100429797847215/4814681571895601/latest.html&quot;&gt;Saving &amp;amp; loading Machine Learning (ML) models&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2728434780191932/1483312212640900/6987336228780374/latest.html&quot;&gt;Subqueries in Apache Spark 2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section-4&quot;&gt;本系列文章链接&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/introduction-to-spark?s=inner&quot;&gt;『 Spark 』1. spark 简介 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-questions-concepts?s=inner&quot;&gt;『 Spark 』2. spark 基本概念解析 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-programming-model?s=inner&quot;&gt;『 Spark 』3. spark 编程模式 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-what-is-rdd?s=inner&quot;&gt;『 Spark 』4. spark 之 RDD &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-resouces-blogs-paper?s=inner&quot;&gt;『 Spark 』5. 这些年，你不能错过的 spark 学习资源 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/deep-into-spark-exection-model?s=inner&quot;&gt;『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-dataframe-introduction?s=inner&quot;&gt;『 Spark 』7. 使用 Spark DataFrame 进行大数据分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-in-finance-and-investing?s=inner&quot;&gt;『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/ipython-notebook-spark?s=inner&quot;&gt;『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/boost-spark-application-performance?s=inner&quot;&gt;『 Spark 』10. spark 应用程序性能优化｜12 个优化方法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-mlib-machine-learning?s=inner&quot;&gt;『 Spark 』11. spark 机器学习&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-2.0-faster-easier-smarter?s=inner&quot;&gt;『 Spark 』12. Spark 2.0 特性介绍&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner&quot;&gt;『 Spark 』13. Spark 2.0 Release Notes 中文版 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://litaotao.github.io/spark-sql-parquet-optimize?s=inner&quot;&gt;『 Spark 』14. 一次 Spark SQL 性能优化之旅&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   
   <entry>
     <title>git 常用命令及一些小技巧</title>
     <link href="/github-commands-and-tricks"/>
     <updated>2016-06-10T00:00:00+08:00</updated>
     <id>/github-commands-and-tricks</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;1. 常用命令&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git init                                                  # 初始化本地git仓库（创建新仓库）

git config --global user.name &quot;xxx&quot;                       # 配置用户名
git config --global user.email &quot;xxx@xxx.com&quot;              # 配置邮件
git config --global color.ui true                         # git status等命令自动着色
git config --global color.status auto
git config --global color.diff auto
git config --global color.branch auto
git config --global color.interactive auto
git config --global --unset http.proxy                    # remove  proxy configuration on git

git clone git+ssh://git@192.168.53.168/VT.git             # clone远程仓库
git status                                                # 查看当前版本状态（是否修改）

git add xyz                                               # 添加xyz文件至index
git add .                                                 # 增加当前子目录下所有更改过的文件至index

git commit -m &#39;xxx&#39;                                       # 提交
git commit --amend -m &#39;xxx&#39;                               # 合并上一次提交（用于反复修改）
git commit -am &#39;xxx&#39;                                      # 将add和commit合为一步

git rm xxx                                                # 删除index中的文件
git rm -r *                                               # 递归删除

git log                                                   # 显示提交日志
git log -1                                                # 显示1行日志 -n为n行
git log -5
git log --stat                                            # 显示提交日志及相关变动文件
git log -p -m
git log v2.0                                              # 显示v2.0的日志

git show dfb02e6e4f2f7b573337763e5c0013802e392818         # 显示某个提交的详细内容
git show dfb02                                            # 可只用commitid的前几位
git show HEAD                                             # 显示HEAD提交日志
git show HEAD^                                            # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本
git show v2.0                                             # 显示v2.0的日志及详细内容
git show HEAD@{5}
git show master@{yesterday}                               # 显示master分支昨天的状态
git show HEAD~3
git show -s --pretty=raw 2be7fcb476

git tag                                                   # 显示已存在的tag
git tag -a v2.0 -m &#39;xxx&#39;                                  # 增加v2.0的tag

git diff                                                  # 显示所有未添加至index的变更
git diff --cached                                         # 显示所有已添加index但还未commit的变更
git diff HEAD^                                            # 比较与上一个版本的差异
git diff HEAD -- ./lib                                    # 比较与HEAD版本lib目录的差异
git diff origin/master..master                            # 比较远程分支master上有本地分支master上没有的
git diff origin/master..master --stat                     # 只显示差异的文件，不显示具体内容

git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch）

git branch                                                # 显示本地分支
git branch --contains 50089                               # 显示包含提交50089的分支
git branch -a                                             # 显示所有分支
git branch -r                                             # 显示所有原创分支
git branch --merged                                       # 显示所有已合并到当前分支的分支
git branch --no-merged                                    # 显示所有未合并到当前分支的分支
git branch -m master master_copy                          # 本地分支改名
git branch -d hotfixes/BJVEP933                           # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支）
git branch -D hotfixes/BJVEP933                           # 强制删除分支hotfixes/BJVEP933
git show-branch                                           # 图示当前分支历史
git show-branch --all                                     # 图示所有分支历史

git checkout -b master_copy                               # 从当前分支创建新分支master_copy并检出
git checkout -b master master_copy                        # 上面的完整版
git checkout features/performance                         # 检出已存在的features/performance分支
git checkout --track hotfixes/BJVEP933                    # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支
git checkout v2.0                                         # 检出版本v2.0
git checkout -b devel origin/develop                      # 从远程分支develop创建新本地分支devel并检出
git checkout -- README                                    # 检出head版本的README文件（可用于修改错误回退）

git merge origin/master                                   # 合并远程master分支至当前分支
git cherry-pick ff44785404a8e                             # 合并提交ff44785404a8e的修改
git push origin master                                    # 将当前分支push到远程master分支
git push origin :hotfixes/BJVEP933                        # 删除远程仓库的hotfixes/BJVEP933分支
git push --tags                                           # 把所有tag推送到远程仓库

git fetch                                                 # 获取所有远程分支（不更新本地分支，另需merge）
git fetch --prune                                         # 获取所有原创分支并清除服务器上已删掉的分支

git pull origin master                                    # 获取远程分支master并merge到当前分支
git mv README README2                                     # 重命名文件README为README2
git reset --hard HEAD                                     # 将当前版本重置为HEAD（通常用于merge失败回退）

git rebase

git ls-files                                              # 列出git index包含的文件
git whatchanged                                           # 显示提交历史对应的文件修改
git revert dfb02e6e4f2f7b573337763e5c0013802e392818       # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818
git ls-tree HEAD                                          # 内部命令：显示某个git对象
git rev-parse v2.0                                        # 内部命令：显示某个ref对于的SHA1 HASH
git reflog                                                # 显示所有提交，包括孤立节点

git log --pretty=format:&#39;%h %s&#39; --graph                   # 图示提交日志

git stash                                                 # 暂存当前修改，将所有至为HEAD状态
git stash list                                            # 查看所有暂存
git stash show -p stash@{0}                               # 参考第一次暂存
git stash apply stash@{0}                                 # 应用第一次暂存

git grep &quot;delete from&quot;                                    # 文件中搜索文本“delete from”
git grep -e &#39;#define&#39; --and -e SORT_DIRENT
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-1&quot;&gt;2. 常用技巧&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;更改分支名字&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git branch -m old_branch new_branch         # Rename branch locally    
git push origin :old_branch                 # Delete the old branch    
git push --set-upstream origin new_branch   # Push the new branch, set local branch to track the new remote
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;多帐户配置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/xirong/my-git/blob/master/use-gitlab-github-together.md&quot;&gt;git 多帐户配置，一台电脑上同时使用 github, gitlab, gitcafe&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;参考文章&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/guweigang/9848271&quot;&gt;git命令大全&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://marklodato.github.io/visual-git-guide/index-en.html&quot;&gt;A Visual Git Reference&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/hutaoer/archive/2012/12/09/3078879.html&quot;&gt;git config命令使用第一篇——介绍，基本操作，增删改查&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/xirong/my-git/blob/master/use-gitlab-github-together.md&quot;&gt;git 多帐户配置，一台电脑上同时使用 github, gitlab, gitcafe&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://backlogtool.com/git-guide/cn/intro/intro1_1.html&quot;&gt;Git的基础&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
   </entry>
   
   <entry>
     <title>Python for Finance, Quant Topic</title>
     <link href="/python-finance-quant-investing"/>
     <updated>2016-06-02T00:00:00+08:00</updated>
     <id>/python-finance-quant-investing</id>
     <content type="html">&lt;h2 id=&quot;section&quot;&gt;写在前面&lt;/h2&gt;

&lt;p&gt;这是我在 2016.06.02 的讲座课件。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;1. 讲稿&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../images/python-quant/python-quant.001.jpeg&quot; alt=&quot;python-quant.001.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.002.jpeg&quot; alt=&quot;python-quant.002.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.003.jpeg&quot; alt=&quot;python-quant.003.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.004.jpeg&quot; alt=&quot;python-quant.004.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.005.jpeg&quot; alt=&quot;python-quant.005.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.006.jpeg&quot; alt=&quot;python-quant.006.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.007.jpeg&quot; alt=&quot;python-quant.007.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.008.jpeg&quot; alt=&quot;python-quant.008.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.009.jpeg&quot; alt=&quot;python-quant.009.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.010.jpeg&quot; alt=&quot;python-quant.0010.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.011.jpeg&quot; alt=&quot;python-quant.0011.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.012.jpeg&quot; alt=&quot;python-quant.0012.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.013.jpeg&quot; alt=&quot;python-quant.0013.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.014.jpeg&quot; alt=&quot;python-quant.0014.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.015.jpeg&quot; alt=&quot;python-quant.0015.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.016.jpeg&quot; alt=&quot;python-quant.0016.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.017.jpeg&quot; alt=&quot;python-quant.0017.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.018.jpeg&quot; alt=&quot;python-quant.0018.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.019.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.020.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.021.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.022.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.023.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.024.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;
&lt;img src=&quot;../images/python-quant/python-quant.025.jpeg&quot; alt=&quot;python-quant.0019.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;讲稿 pdf 版：&lt;a href=&quot;http://litaotao.github.io/files/python-quant-uqer.pdf&quot;&gt;python-quant-uqer.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;2. 参考文档&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/575113fa228e5b869e1fc5f2&quot;&gt;『06.02 公开课』1. Python Basics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/57511416228e5b86ad1fd44b&quot;&gt;『06.02 公开课』2. First Show of Pandas&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/57511423228e5b86a51fd996&quot;&gt;『06.02 公开课』3. First Show of Numpy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/57511433228e5b86a21fca85&quot;&gt;『06.02 公开课』4. First Show of Matplotlib&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/5751144e228e5b86a51fd997&quot;&gt;『06.02 公开课』5. First Show of Sklearn&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/57511469228e5b86a31fcdf4&quot;&gt;『06.02 公开课』6. Python Quant UQER&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://uqer.io/community/share/57511520228e5b86b11fd182&quot;&gt;『06.02 公开课』7. share_0602 函数库&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
   </entry>
   

</feed>



  <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1258855744'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1258855744' type='text/javascript'%3E%3C/script%3E"));
  </script>

</body>
</html>
